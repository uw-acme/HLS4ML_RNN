{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9726c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Flatten, GRU,TimeDistributed, Conv1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l1\n",
    "import ast\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from scipy.stats import loguniform\n",
    "# from pandas import read_csv\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from datetime import datetime\n",
    "from qkeras import *\n",
    "today = datetime.date(datetime.now())\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import model_save_quantized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d2b63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "755868e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outdir = \"/global/homes/e/elham/rnn_hls4ml/results/\"\n",
    "outpath = \"gru_training_2022-08-09\"\n",
    "#comd = \"mkdir \"+outpath\n",
    "#os.system(comd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a0cd0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputdir = 'rnn_hls4ml_data_scaled'\n",
    "inputdir = 'rnn_hls4ml_data_scaled_2class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1952985d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y-shape:  (379052, 1)\n",
      "x-shape:  (379052, 20, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.load('./x_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "\n",
    "y_train = y_train[:,4:5]\n",
    "plt.hist(y_train)\n",
    "\n",
    "print(\"y-shape: \", y_train.shape)\n",
    "print(\"x-shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96b2bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b39ed50",
   "metadata": {},
   "source": [
    "## Small GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfde4ae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 10:17:30.501174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (GRU)                (None, 5)                 195       \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 5)                 30        \n",
      "                                                                 \n",
      " output_sigmoid (Dense)      (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(5, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "              name = 'layer1', input_shape = (20,6)))\n",
    "model.add(Dense(5, activation='relu', kernel_initializer='glorot_normal', name='layer2'))\n",
    "model.add(Dense(1, activation='sigmoid', name = 'output_sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23d020",
   "metadata": {},
   "source": [
    "## Small QGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c490b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (QGRU)               (None, 5)                 180       \n",
      "                                                                 \n",
      " layer2 (QDense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " output_sigmoid (QDense)     (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216\n",
      "Trainable params: 216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qmodel = Sequential()\n",
    "qmodel.add(QGRU(5, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "                name = 'layer1', kernel_quantizer=quantized_bits(2,0,alpha=1),\n",
    "                recurrent_quantizer=quantized_bits(2,0,alpha=1) , bias_quantizer=quantized_bits(2,0,alpha=1),\n",
    "                state_quantizer=quantized_bits(2,0,alpha=1) ,input_shape = (20,6)))\n",
    "qmodel.add(QDense(5, activation='relu', kernel_initializer='glorot_normal', kernel_quantizer=quantized_bits(2,0,alpha=1),\n",
    "                  bias_quantizer=quantized_bits(2,0,alpha=1), name='layer2'))\n",
    "qmodel.add(QDense(1, activation='sigmoid', kernel_quantizer=quantized_bits(2,0,alpha=1),\n",
    "                  bias_quantizer=quantized_bits(2,0,alpha=1), name = 'output_sigmoid'))\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18329a8",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2527b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (GRU)                (None, 20)                1680      \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 64)                1344      \n",
      "                                                                 \n",
      " relu_0 (Activation)         (None, 64)                0         \n",
      "                                                                 \n",
      " output_sigmoid (Dense)      (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,089\n",
      "Trainable params: 3,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(20, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001), name = 'layer1', input_shape = (20,6)))\n",
    "model.add(Dense(64,  kernel_initializer='glorot_normal', name='layer3')) #kernel_regularizer = regularizers.l1_l2(l1= 0.0001, l2 = 0.0001),\n",
    "model.add(Activation('relu', name = 'relu_0'))\n",
    "model.add(Dense(1, activation='sigmoid', name = 'output_sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1068021",
   "metadata": {},
   "source": [
    "## GRU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c0c0635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyihu\\anaconda3\\envs\\hls4ml-tutorial\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.7547\n",
      "Epoch 1: val_loss improved from inf to 0.38766, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 4s 8ms/step - loss: 0.5157 - accuracy: 0.7547 - val_loss: 0.3877 - val_accuracy: 0.8408\n",
      "Epoch 2/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8391\n",
      "Epoch 2: val_loss improved from 0.38766 to 0.38110, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3905 - accuracy: 0.8391 - val_loss: 0.3811 - val_accuracy: 0.8433\n",
      "Epoch 3/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8418\n",
      "Epoch 3: val_loss did not improve from 0.38110\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3848 - accuracy: 0.8418 - val_loss: 0.3998 - val_accuracy: 0.8336\n",
      "Epoch 4/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8422\n",
      "Epoch 4: val_loss improved from 0.38110 to 0.37669, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3830 - accuracy: 0.8422 - val_loss: 0.3767 - val_accuracy: 0.8453\n",
      "Epoch 5/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8429\n",
      "Epoch 5: val_loss improved from 0.37669 to 0.37403, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3806 - accuracy: 0.8431 - val_loss: 0.3740 - val_accuracy: 0.8462\n",
      "Epoch 6/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8433\n",
      "Epoch 6: val_loss improved from 0.37403 to 0.37191, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3799 - accuracy: 0.8434 - val_loss: 0.3719 - val_accuracy: 0.8470\n",
      "Epoch 7/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8449\n",
      "Epoch 7: val_loss did not improve from 0.37191\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3769 - accuracy: 0.8448 - val_loss: 0.3754 - val_accuracy: 0.8459\n",
      "Epoch 8/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3760 - accuracy: 0.8450\n",
      "Epoch 8: val_loss improved from 0.37191 to 0.36813, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3760 - accuracy: 0.8450 - val_loss: 0.3681 - val_accuracy: 0.8492\n",
      "Epoch 9/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.8466\n",
      "Epoch 9: val_loss improved from 0.36813 to 0.36589, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3730 - accuracy: 0.8464 - val_loss: 0.3659 - val_accuracy: 0.8502\n",
      "Epoch 10/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3717 - accuracy: 0.8465\n",
      "Epoch 10: val_loss did not improve from 0.36589\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3717 - accuracy: 0.8465 - val_loss: 0.3671 - val_accuracy: 0.8492\n",
      "Epoch 11/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3679 - accuracy: 0.8488\n",
      "Epoch 11: val_loss did not improve from 0.36589\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3679 - accuracy: 0.8488 - val_loss: 0.3714 - val_accuracy: 0.8462\n",
      "Epoch 12/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.8484\n",
      "Epoch 12: val_loss improved from 0.36589 to 0.36037, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3674 - accuracy: 0.8485 - val_loss: 0.3604 - val_accuracy: 0.8523\n",
      "Epoch 13/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.8498\n",
      "Epoch 13: val_loss did not improve from 0.36037\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3647 - accuracy: 0.8499 - val_loss: 0.3619 - val_accuracy: 0.8514\n",
      "Epoch 14/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.8501\n",
      "Epoch 14: val_loss improved from 0.36037 to 0.35659, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3646 - accuracy: 0.8501 - val_loss: 0.3566 - val_accuracy: 0.8544\n",
      "Epoch 15/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3617 - accuracy: 0.8507\n",
      "Epoch 15: val_loss did not improve from 0.35659\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3615 - accuracy: 0.8510 - val_loss: 0.3612 - val_accuracy: 0.8532\n",
      "Epoch 16/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.8510\n",
      "Epoch 16: val_loss did not improve from 0.35659\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3613 - accuracy: 0.8511 - val_loss: 0.3697 - val_accuracy: 0.8469\n",
      "Epoch 17/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.8507\n",
      "Epoch 17: val_loss did not improve from 0.35659\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3620 - accuracy: 0.8507 - val_loss: 0.3668 - val_accuracy: 0.8497\n",
      "Epoch 18/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3606 - accuracy: 0.8510\n",
      "Epoch 18: val_loss did not improve from 0.35659\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3607 - accuracy: 0.8510 - val_loss: 0.3794 - val_accuracy: 0.8435\n",
      "Epoch 19/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8518\n",
      "Epoch 19: val_loss did not improve from 0.35659\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3591 - accuracy: 0.8518 - val_loss: 0.3627 - val_accuracy: 0.8519\n",
      "Epoch 20/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.8521\n",
      "Epoch 20: val_loss improved from 0.35659 to 0.35275, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3587 - accuracy: 0.8521 - val_loss: 0.3527 - val_accuracy: 0.8559\n",
      "Epoch 21/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.8520\n",
      "Epoch 21: val_loss did not improve from 0.35275\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3573 - accuracy: 0.8522 - val_loss: 0.3581 - val_accuracy: 0.8522\n",
      "Epoch 22/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3570 - accuracy: 0.8526\n",
      "Epoch 22: val_loss did not improve from 0.35275\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3570 - accuracy: 0.8526 - val_loss: 0.3548 - val_accuracy: 0.8542\n",
      "Epoch 23/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3565 - accuracy: 0.8523\n",
      "Epoch 23: val_loss improved from 0.35275 to 0.35020, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3565 - accuracy: 0.8524 - val_loss: 0.3502 - val_accuracy: 0.8562\n",
      "Epoch 24/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3562 - accuracy: 0.8526\n",
      "Epoch 24: val_loss did not improve from 0.35020\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3562 - accuracy: 0.8526 - val_loss: 0.3517 - val_accuracy: 0.8559\n",
      "Epoch 25/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3564 - accuracy: 0.8522\n",
      "Epoch 25: val_loss did not improve from 0.35020\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3564 - accuracy: 0.8522 - val_loss: 0.3615 - val_accuracy: 0.8504\n",
      "Epoch 26/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.8526\n",
      "Epoch 26: val_loss did not improve from 0.35020\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3549 - accuracy: 0.8527 - val_loss: 0.3700 - val_accuracy: 0.8475\n",
      "Epoch 27/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.8535\n",
      "Epoch 27: val_loss did not improve from 0.35020\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3550 - accuracy: 0.8533 - val_loss: 0.3745 - val_accuracy: 0.8451\n",
      "Epoch 28/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.8529\n",
      "Epoch 28: val_loss did not improve from 0.35020\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3546 - accuracy: 0.8529 - val_loss: 0.3712 - val_accuracy: 0.8468\n",
      "Epoch 29/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.8531\n",
      "Epoch 29: val_loss improved from 0.35020 to 0.34922, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3543 - accuracy: 0.8532 - val_loss: 0.3492 - val_accuracy: 0.8559\n",
      "Epoch 30/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8533\n",
      "Epoch 30: val_loss did not improve from 0.34922\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3535 - accuracy: 0.8533 - val_loss: 0.3510 - val_accuracy: 0.8555\n",
      "Epoch 31/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8536\n",
      "Epoch 31: val_loss did not improve from 0.34922\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3531 - accuracy: 0.8535 - val_loss: 0.3496 - val_accuracy: 0.8571\n",
      "Epoch 32/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8539\n",
      "Epoch 32: val_loss did not improve from 0.34922\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3527 - accuracy: 0.8539 - val_loss: 0.3691 - val_accuracy: 0.8481\n",
      "Epoch 33/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3535 - accuracy: 0.8533\n",
      "Epoch 33: val_loss improved from 0.34922 to 0.34740, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3535 - accuracy: 0.8533 - val_loss: 0.3474 - val_accuracy: 0.8572\n",
      "Epoch 34/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3521 - accuracy: 0.8537\n",
      "Epoch 34: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3522 - accuracy: 0.8537 - val_loss: 0.3487 - val_accuracy: 0.8559\n",
      "Epoch 35/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8540\n",
      "Epoch 35: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3518 - accuracy: 0.8540 - val_loss: 0.3475 - val_accuracy: 0.8567\n",
      "Epoch 36/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3513 - accuracy: 0.8542\n",
      "Epoch 36: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3517 - accuracy: 0.8540 - val_loss: 0.3515 - val_accuracy: 0.8560\n",
      "Epoch 37/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8536\n",
      "Epoch 37: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3521 - accuracy: 0.8536 - val_loss: 0.3513 - val_accuracy: 0.8562\n",
      "Epoch 38/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8539\n",
      "Epoch 38: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3522 - accuracy: 0.8539 - val_loss: 0.3489 - val_accuracy: 0.8569\n",
      "Epoch 39/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8546\n",
      "Epoch 39: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3511 - accuracy: 0.8546 - val_loss: 0.3732 - val_accuracy: 0.8438\n",
      "Epoch 40/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8534\n",
      "Epoch 40: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3530 - accuracy: 0.8533 - val_loss: 0.3593 - val_accuracy: 0.8517\n",
      "Epoch 41/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.8544\n",
      "Epoch 41: val_loss did not improve from 0.34740\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3507 - accuracy: 0.8544 - val_loss: 0.3513 - val_accuracy: 0.8578\n",
      "Epoch 42/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3517 - accuracy: 0.8543\n",
      "Epoch 42: val_loss improved from 0.34740 to 0.34433, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3517 - accuracy: 0.8541 - val_loss: 0.3443 - val_accuracy: 0.8583\n",
      "Epoch 43/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8536\n",
      "Epoch 43: val_loss did not improve from 0.34433\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3525 - accuracy: 0.8534 - val_loss: 0.3461 - val_accuracy: 0.8575\n",
      "Epoch 44/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8544\n",
      "Epoch 44: val_loss improved from 0.34433 to 0.34404, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3498 - accuracy: 0.8545 - val_loss: 0.3440 - val_accuracy: 0.8582\n",
      "Epoch 45/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.8542\n",
      "Epoch 45: val_loss did not improve from 0.34404\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3506 - accuracy: 0.8541 - val_loss: 0.3488 - val_accuracy: 0.8573\n",
      "Epoch 46/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3506 - accuracy: 0.8543\n",
      "Epoch 46: val_loss improved from 0.34404 to 0.34386, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3505 - accuracy: 0.8543 - val_loss: 0.3439 - val_accuracy: 0.8584\n",
      "Epoch 47/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3510 - accuracy: 0.8545\n",
      "Epoch 47: val_loss did not improve from 0.34386\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3511 - accuracy: 0.8545 - val_loss: 0.3543 - val_accuracy: 0.8526\n",
      "Epoch 48/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.8550\n",
      "Epoch 48: val_loss did not improve from 0.34386\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3491 - accuracy: 0.8550 - val_loss: 0.3465 - val_accuracy: 0.8579\n",
      "Epoch 49/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3501 - accuracy: 0.8546\n",
      "Epoch 49: val_loss improved from 0.34386 to 0.34321, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3498 - accuracy: 0.8547 - val_loss: 0.3432 - val_accuracy: 0.8583\n",
      "Epoch 50/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8550\n",
      "Epoch 50: val_loss did not improve from 0.34321\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3488 - accuracy: 0.8550 - val_loss: 0.3437 - val_accuracy: 0.8581\n",
      "Epoch 51/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8547\n",
      "Epoch 51: val_loss did not improve from 0.34321\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3489 - accuracy: 0.8547 - val_loss: 0.3461 - val_accuracy: 0.8569\n",
      "Epoch 52/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8547\n",
      "Epoch 52: val_loss did not improve from 0.34321\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3500 - accuracy: 0.8547 - val_loss: 0.3471 - val_accuracy: 0.8575\n",
      "Epoch 53/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3486 - accuracy: 0.8551\n",
      "Epoch 53: val_loss improved from 0.34321 to 0.34268, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3486 - accuracy: 0.8551 - val_loss: 0.3427 - val_accuracy: 0.8585\n",
      "Epoch 54/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8549\n",
      "Epoch 54: val_loss did not improve from 0.34268\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3488 - accuracy: 0.8549 - val_loss: 0.3444 - val_accuracy: 0.8578\n",
      "Epoch 55/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3478 - accuracy: 0.8553\n",
      "Epoch 55: val_loss did not improve from 0.34268\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3478 - accuracy: 0.8553 - val_loss: 0.3495 - val_accuracy: 0.8566\n",
      "Epoch 56/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3471 - accuracy: 0.8556\n",
      "Epoch 56: val_loss did not improve from 0.34268\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3472 - accuracy: 0.8555 - val_loss: 0.3434 - val_accuracy: 0.8580\n",
      "Epoch 57/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.8553\n",
      "Epoch 57: val_loss did not improve from 0.34268\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3474 - accuracy: 0.8553 - val_loss: 0.3523 - val_accuracy: 0.8553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "286/297 [===========================>..] - ETA: 0s - loss: 0.3493 - accuracy: 0.8553\n",
      "Epoch 58: val_loss did not improve from 0.34268\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3493 - accuracy: 0.8553 - val_loss: 0.3447 - val_accuracy: 0.8580\n",
      "Epoch 59/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8555\n",
      "Epoch 59: val_loss improved from 0.34268 to 0.34178, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3475 - accuracy: 0.8556 - val_loss: 0.3418 - val_accuracy: 0.8588\n",
      "Epoch 60/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.8552\n",
      "Epoch 60: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3475 - accuracy: 0.8552 - val_loss: 0.3422 - val_accuracy: 0.8589\n",
      "Epoch 61/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3464 - accuracy: 0.8558\n",
      "Epoch 61: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3463 - accuracy: 0.8558 - val_loss: 0.3426 - val_accuracy: 0.8580\n",
      "Epoch 62/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.8558\n",
      "Epoch 62: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3464 - accuracy: 0.8560 - val_loss: 0.3501 - val_accuracy: 0.8550\n",
      "Epoch 63/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.8560\n",
      "Epoch 63: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3464 - accuracy: 0.8561 - val_loss: 0.3576 - val_accuracy: 0.8518\n",
      "Epoch 64/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.8561\n",
      "Epoch 64: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3469 - accuracy: 0.8560 - val_loss: 0.3506 - val_accuracy: 0.8568\n",
      "Epoch 65/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.8561\n",
      "Epoch 65: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3458 - accuracy: 0.8562 - val_loss: 0.3426 - val_accuracy: 0.8593\n",
      "Epoch 66/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3461 - accuracy: 0.8563\n",
      "Epoch 66: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3461 - accuracy: 0.8562 - val_loss: 0.3433 - val_accuracy: 0.8578\n",
      "Epoch 67/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8559\n",
      "Epoch 67: val_loss did not improve from 0.34178\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3462 - accuracy: 0.8559 - val_loss: 0.3485 - val_accuracy: 0.8572\n",
      "Epoch 68/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.8567\n",
      "Epoch 68: val_loss improved from 0.34178 to 0.34032, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3447 - accuracy: 0.8566 - val_loss: 0.3403 - val_accuracy: 0.8593\n",
      "Epoch 69/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3448 - accuracy: 0.8564\n",
      "Epoch 69: val_loss did not improve from 0.34032\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3448 - accuracy: 0.8564 - val_loss: 0.3433 - val_accuracy: 0.8568\n",
      "Epoch 70/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8569\n",
      "Epoch 70: val_loss did not improve from 0.34032\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3439 - accuracy: 0.8569 - val_loss: 0.3440 - val_accuracy: 0.8585\n",
      "Epoch 71/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.8569\n",
      "Epoch 71: val_loss did not improve from 0.34032\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3447 - accuracy: 0.8567 - val_loss: 0.3410 - val_accuracy: 0.8595\n",
      "Epoch 72/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.8569\n",
      "Epoch 72: val_loss improved from 0.34032 to 0.34009, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3449 - accuracy: 0.8570 - val_loss: 0.3401 - val_accuracy: 0.8593\n",
      "Epoch 73/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3441 - accuracy: 0.8571\n",
      "Epoch 73: val_loss did not improve from 0.34009\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3440 - accuracy: 0.8572 - val_loss: 0.3435 - val_accuracy: 0.8590\n",
      "Epoch 74/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3447 - accuracy: 0.8567\n",
      "Epoch 74: val_loss did not improve from 0.34009\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3444 - accuracy: 0.8569 - val_loss: 0.3560 - val_accuracy: 0.8554\n",
      "Epoch 75/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.8565\n",
      "Epoch 75: val_loss improved from 0.34009 to 0.33911, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3449 - accuracy: 0.8565 - val_loss: 0.3391 - val_accuracy: 0.8604\n",
      "Epoch 76/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.8563\n",
      "Epoch 76: val_loss did not improve from 0.33911\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3448 - accuracy: 0.8564 - val_loss: 0.3448 - val_accuracy: 0.8575\n",
      "Epoch 77/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8570\n",
      "Epoch 77: val_loss did not improve from 0.33911\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3432 - accuracy: 0.8571 - val_loss: 0.3409 - val_accuracy: 0.8591\n",
      "Epoch 78/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8572\n",
      "Epoch 78: val_loss did not improve from 0.33911\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3433 - accuracy: 0.8571 - val_loss: 0.3421 - val_accuracy: 0.8591\n",
      "Epoch 79/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3441 - accuracy: 0.8571\n",
      "Epoch 79: val_loss improved from 0.33911 to 0.33834, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3439 - accuracy: 0.8572 - val_loss: 0.3383 - val_accuracy: 0.8609\n",
      "Epoch 80/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3430 - accuracy: 0.8574\n",
      "Epoch 80: val_loss did not improve from 0.33834\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3430 - accuracy: 0.8574 - val_loss: 0.3482 - val_accuracy: 0.8559\n",
      "Epoch 81/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3440 - accuracy: 0.8573\n",
      "Epoch 81: val_loss did not improve from 0.33834\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3441 - accuracy: 0.8571 - val_loss: 0.3452 - val_accuracy: 0.8585\n",
      "Epoch 82/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3436 - accuracy: 0.8572\n",
      "Epoch 82: val_loss did not improve from 0.33834\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3437 - accuracy: 0.8571 - val_loss: 0.3675 - val_accuracy: 0.8460\n",
      "Epoch 83/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3439 - accuracy: 0.8567\n",
      "Epoch 83: val_loss did not improve from 0.33834\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3441 - accuracy: 0.8565 - val_loss: 0.3412 - val_accuracy: 0.8600\n",
      "Epoch 84/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3429 - accuracy: 0.8576\n",
      "Epoch 84: val_loss improved from 0.33834 to 0.33715, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3428 - accuracy: 0.8577 - val_loss: 0.3372 - val_accuracy: 0.8610\n",
      "Epoch 85/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8574\n",
      "Epoch 85: val_loss did not improve from 0.33715\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3425 - accuracy: 0.8574 - val_loss: 0.3521 - val_accuracy: 0.8538\n",
      "Epoch 86/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3430 - accuracy: 0.8574\n",
      "Epoch 86: val_loss did not improve from 0.33715\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3430 - accuracy: 0.8574 - val_loss: 0.3405 - val_accuracy: 0.8591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.8581\n",
      "Epoch 87: val_loss improved from 0.33715 to 0.33665, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3424 - accuracy: 0.8581 - val_loss: 0.3366 - val_accuracy: 0.8611\n",
      "Epoch 88/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8578\n",
      "Epoch 88: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3426 - accuracy: 0.8577 - val_loss: 0.3438 - val_accuracy: 0.8582\n",
      "Epoch 89/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8575\n",
      "Epoch 89: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3426 - accuracy: 0.8574 - val_loss: 0.3419 - val_accuracy: 0.8590\n",
      "Epoch 90/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.8574\n",
      "Epoch 90: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3432 - accuracy: 0.8574 - val_loss: 0.3377 - val_accuracy: 0.8612\n",
      "Epoch 91/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8580\n",
      "Epoch 91: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3428 - accuracy: 0.8581 - val_loss: 0.3374 - val_accuracy: 0.8616\n",
      "Epoch 92/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8572\n",
      "Epoch 92: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3428 - accuracy: 0.8573 - val_loss: 0.3385 - val_accuracy: 0.8600\n",
      "Epoch 93/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.8572\n",
      "Epoch 93: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8572 - val_loss: 0.3383 - val_accuracy: 0.8610\n",
      "Epoch 94/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3417 - accuracy: 0.8578\n",
      "Epoch 94: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3417 - accuracy: 0.8578 - val_loss: 0.3396 - val_accuracy: 0.8607\n",
      "Epoch 95/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8579\n",
      "Epoch 95: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3418 - accuracy: 0.8579 - val_loss: 0.3389 - val_accuracy: 0.8603\n",
      "Epoch 96/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3417 - accuracy: 0.8579\n",
      "Epoch 96: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3416 - accuracy: 0.8580 - val_loss: 0.3379 - val_accuracy: 0.8616\n",
      "Epoch 97/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.8576\n",
      "Epoch 97: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3425 - accuracy: 0.8575 - val_loss: 0.3386 - val_accuracy: 0.8595\n",
      "Epoch 98/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.8583\n",
      "Epoch 98: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3415 - accuracy: 0.8580 - val_loss: 0.3590 - val_accuracy: 0.8493\n",
      "Epoch 99/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3430 - accuracy: 0.8572\n",
      "Epoch 99: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3429 - accuracy: 0.8572 - val_loss: 0.3383 - val_accuracy: 0.8609\n",
      "Epoch 100/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.8583\n",
      "Epoch 100: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3409 - accuracy: 0.8583 - val_loss: 0.3389 - val_accuracy: 0.8611\n",
      "Epoch 101/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.8582\n",
      "Epoch 101: val_loss did not improve from 0.33665\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3413 - accuracy: 0.8581 - val_loss: 0.3379 - val_accuracy: 0.8609\n",
      "Epoch 102/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3408 - accuracy: 0.8585\n",
      "Epoch 102: val_loss improved from 0.33665 to 0.33585, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3409 - accuracy: 0.8585 - val_loss: 0.3359 - val_accuracy: 0.8616\n",
      "Epoch 103/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3416 - accuracy: 0.8579\n",
      "Epoch 103: val_loss did not improve from 0.33585\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3416 - accuracy: 0.8579 - val_loss: 0.3429 - val_accuracy: 0.8587\n",
      "Epoch 104/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3412 - accuracy: 0.8585\n",
      "Epoch 104: val_loss did not improve from 0.33585\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3414 - accuracy: 0.8584 - val_loss: 0.3393 - val_accuracy: 0.8609\n",
      "Epoch 105/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8582\n",
      "Epoch 105: val_loss did not improve from 0.33585\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3406 - accuracy: 0.8582 - val_loss: 0.3387 - val_accuracy: 0.8600\n",
      "Epoch 106/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8583\n",
      "Epoch 106: val_loss improved from 0.33585 to 0.33581, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3409 - accuracy: 0.8583 - val_loss: 0.3358 - val_accuracy: 0.8618\n",
      "Epoch 107/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3399 - accuracy: 0.8590\n",
      "Epoch 107: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3399 - accuracy: 0.8589 - val_loss: 0.3361 - val_accuracy: 0.8616\n",
      "Epoch 108/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8586\n",
      "Epoch 108: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3408 - accuracy: 0.8585 - val_loss: 0.3362 - val_accuracy: 0.8614\n",
      "Epoch 109/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.8580\n",
      "Epoch 109: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3414 - accuracy: 0.8581 - val_loss: 0.3415 - val_accuracy: 0.8590\n",
      "Epoch 110/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.8585\n",
      "Epoch 110: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.8584 - val_loss: 0.3417 - val_accuracy: 0.8604\n",
      "Epoch 111/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8582\n",
      "Epoch 111: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3402 - accuracy: 0.8582 - val_loss: 0.3358 - val_accuracy: 0.8614\n",
      "Epoch 112/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8586\n",
      "Epoch 112: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3403 - accuracy: 0.8586 - val_loss: 0.3361 - val_accuracy: 0.8616\n",
      "Epoch 113/150\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.8583\n",
      "Epoch 113: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.8584 - val_loss: 0.3376 - val_accuracy: 0.8604\n",
      "Epoch 114/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.8583\n",
      "Epoch 114: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3402 - accuracy: 0.8582 - val_loss: 0.3369 - val_accuracy: 0.8611\n",
      "Epoch 115/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.8587\n",
      "Epoch 115: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3400 - accuracy: 0.8587 - val_loss: 0.3516 - val_accuracy: 0.8551\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/297 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8587\n",
      "Epoch 116: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3401 - accuracy: 0.8588 - val_loss: 0.3373 - val_accuracy: 0.8609\n",
      "Epoch 117/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.8581\n",
      "Epoch 117: val_loss did not improve from 0.33581\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.8580 - val_loss: 0.3365 - val_accuracy: 0.8617\n",
      "Epoch 118/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.8589\n",
      "Epoch 118: val_loss improved from 0.33581 to 0.33533, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3396 - accuracy: 0.8588 - val_loss: 0.3353 - val_accuracy: 0.8612\n",
      "Epoch 119/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8589\n",
      "Epoch 119: val_loss did not improve from 0.33533\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3387 - accuracy: 0.8589 - val_loss: 0.3381 - val_accuracy: 0.8605\n",
      "Epoch 120/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.8587\n",
      "Epoch 120: val_loss did not improve from 0.33533\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3393 - accuracy: 0.8587 - val_loss: 0.3546 - val_accuracy: 0.8543\n",
      "Epoch 121/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.8591\n",
      "Epoch 121: val_loss did not improve from 0.33533\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3394 - accuracy: 0.8590 - val_loss: 0.3374 - val_accuracy: 0.8612\n",
      "Epoch 122/150\n",
      "286/297 [===========================>..] - ETA: 0s - loss: 0.3391 - accuracy: 0.8592\n",
      "Epoch 122: val_loss improved from 0.33533 to 0.33453, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3391 - accuracy: 0.8591 - val_loss: 0.3345 - val_accuracy: 0.8619\n",
      "Epoch 123/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8589\n",
      "Epoch 123: val_loss did not improve from 0.33453\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3399 - accuracy: 0.8589 - val_loss: 0.3360 - val_accuracy: 0.8615\n",
      "Epoch 124/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.8589\n",
      "Epoch 124: val_loss did not improve from 0.33453\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3394 - accuracy: 0.8588 - val_loss: 0.3371 - val_accuracy: 0.8600\n",
      "Epoch 125/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.8582\n",
      "Epoch 125: val_loss did not improve from 0.33453\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3398 - accuracy: 0.8582 - val_loss: 0.3538 - val_accuracy: 0.8527\n",
      "Epoch 126/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.8592\n",
      "Epoch 126: val_loss did not improve from 0.33453\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3390 - accuracy: 0.8591 - val_loss: 0.3364 - val_accuracy: 0.8609\n",
      "Epoch 127/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.8594\n",
      "Epoch 127: val_loss did not improve from 0.33453\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3382 - accuracy: 0.8595 - val_loss: 0.3348 - val_accuracy: 0.8622\n",
      "Epoch 128/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.8591\n",
      "Epoch 128: val_loss improved from 0.33453 to 0.33385, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3392 - accuracy: 0.8591 - val_loss: 0.3339 - val_accuracy: 0.8621\n",
      "Epoch 129/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.8595\n",
      "Epoch 129: val_loss did not improve from 0.33385\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3378 - accuracy: 0.8593 - val_loss: 0.3375 - val_accuracy: 0.8609\n",
      "Epoch 130/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.8592\n",
      "Epoch 130: val_loss did not improve from 0.33385\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3380 - accuracy: 0.8592 - val_loss: 0.3347 - val_accuracy: 0.8624\n",
      "Epoch 131/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.8591\n",
      "Epoch 131: val_loss did not improve from 0.33385\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3387 - accuracy: 0.8591 - val_loss: 0.3339 - val_accuracy: 0.8613\n",
      "Epoch 132/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3380 - accuracy: 0.8592\n",
      "Epoch 132: val_loss did not improve from 0.33385\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3381 - accuracy: 0.8591 - val_loss: 0.3385 - val_accuracy: 0.8610\n",
      "Epoch 133/150\n",
      "288/297 [============================>.] - ETA: 0s - loss: 0.3380 - accuracy: 0.8594\n",
      "Epoch 133: val_loss improved from 0.33385 to 0.33264, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3380 - accuracy: 0.8595 - val_loss: 0.3326 - val_accuracy: 0.8621\n",
      "Epoch 134/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.8601\n",
      "Epoch 134: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3373 - accuracy: 0.8601 - val_loss: 0.3361 - val_accuracy: 0.8610\n",
      "Epoch 135/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.8593\n",
      "Epoch 135: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3375 - accuracy: 0.8593 - val_loss: 0.3353 - val_accuracy: 0.8615\n",
      "Epoch 136/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.8594\n",
      "Epoch 136: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3378 - accuracy: 0.8594 - val_loss: 0.3406 - val_accuracy: 0.8585\n",
      "Epoch 137/150\n",
      "290/297 [============================>.] - ETA: 0s - loss: 0.3365 - accuracy: 0.8599\n",
      "Epoch 137: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3364 - accuracy: 0.8599 - val_loss: 0.3332 - val_accuracy: 0.8622\n",
      "Epoch 138/150\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.8599\n",
      "Epoch 138: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3370 - accuracy: 0.8599 - val_loss: 0.3337 - val_accuracy: 0.8617\n",
      "Epoch 139/150\n",
      "287/297 [===========================>..] - ETA: 0s - loss: 0.3371 - accuracy: 0.8596\n",
      "Epoch 139: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3368 - accuracy: 0.8598 - val_loss: 0.3352 - val_accuracy: 0.8620\n",
      "Epoch 140/150\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8596\n",
      "Epoch 140: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.3371 - accuracy: 0.8596 - val_loss: 0.3363 - val_accuracy: 0.8607\n",
      "Epoch 141/150\n",
      "286/297 [===========================>..] - ETA: 0s - loss: 0.3383 - accuracy: 0.8591\n",
      "Epoch 141: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3381 - accuracy: 0.8592 - val_loss: 0.3335 - val_accuracy: 0.8617\n",
      "Epoch 142/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3375 - accuracy: 0.8597\n",
      "Epoch 142: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3374 - accuracy: 0.8597 - val_loss: 0.3415 - val_accuracy: 0.8583\n",
      "Epoch 143/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.8601\n",
      "Epoch 143: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3361 - accuracy: 0.8602 - val_loss: 0.3334 - val_accuracy: 0.8618\n",
      "Epoch 144/150\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.8597\n",
      "Epoch 144: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3368 - accuracy: 0.8596 - val_loss: 0.3371 - val_accuracy: 0.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.8603\n",
      "Epoch 145: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3364 - accuracy: 0.8603 - val_loss: 0.3381 - val_accuracy: 0.8593\n",
      "Epoch 146/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3363 - accuracy: 0.8599\n",
      "Epoch 146: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3363 - accuracy: 0.8598 - val_loss: 0.3417 - val_accuracy: 0.8585\n",
      "Epoch 147/150\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8601\n",
      "Epoch 147: val_loss did not improve from 0.33264\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3360 - accuracy: 0.8602 - val_loss: 0.3329 - val_accuracy: 0.8617\n",
      "Epoch 148/150\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.8605\n",
      "Epoch 148: val_loss improved from 0.33264 to 0.33258, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3357 - accuracy: 0.8605 - val_loss: 0.3326 - val_accuracy: 0.8621\n",
      "Epoch 149/150\n",
      "289/297 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.8604\n",
      "Epoch 149: val_loss improved from 0.33258 to 0.33119, saving model to gru\\model_gru.h5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3355 - accuracy: 0.8605 - val_loss: 0.3312 - val_accuracy: 0.8626\n",
      "Epoch 150/150\n",
      "291/297 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8601\n",
      "Epoch 150: val_loss did not improve from 0.33119\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.3361 - accuracy: 0.8600 - val_loss: 0.3345 - val_accuracy: 0.8616\n",
      "624/624 [==============================] - 1s 2ms/step\n",
      "0.9307736230093996\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=20)\n",
    "adam = Adam(lr = 0.0002)\n",
    "    \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 2**10,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint(f'gru/model_gru.h5', verbose=1, save_best_only=True), es],\n",
    "                    use_multiprocessing=True, workers=4)\n",
    "        \n",
    "labels = ['j_t']\n",
    "y_keras = model.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295b742",
   "metadata": {},
   "source": [
    "## Check GRU Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e57146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 [array([[ 3.85863095e-04, -4.31572989e-05, -8.73781159e-04,\n",
      "        -1.92459358e-03,  1.29464571e-03, -7.83140678e-03,\n",
      "        -4.52704169e-03, -3.65656661e-03, -3.18534370e-03,\n",
      "         3.37608485e-03,  3.79501667e-04,  1.43090059e-04,\n",
      "        -2.91849719e-04,  8.80206935e-04,  1.11935418e-02,\n",
      "        -8.25973451e-02,  9.25967994e-04,  3.15461159e-02,\n",
      "         1.89862424e-03, -9.26391571e-04,  1.34568941e-03,\n",
      "        -3.21646483e-04, -3.17244732e-04,  9.94211645e-04,\n",
      "        -1.33366417e-03, -9.53792632e-02,  5.20681147e-04,\n",
      "        -6.92073663e-04, -5.64584276e-04,  2.83501897e-04,\n",
      "        -1.50891044e-03, -8.75553465e-04,  1.81423943e-03,\n",
      "        -1.65851277e-04,  1.15897600e-03,  1.42314332e-03,\n",
      "        -2.79614981e-03,  3.73507763e-04, -2.02249549e-03,\n",
      "        -1.82630494e-04, -3.94495055e-02,  8.40177685e-02,\n",
      "        -7.14575201e-02,  4.64393914e-01, -6.57469153e-01,\n",
      "        -6.35456562e-01,  4.78052169e-01, -2.35041808e-02,\n",
      "         2.84459330e-02,  3.76566380e-01,  6.80976212e-01,\n",
      "        -1.67928692e-02,  1.08093135e-01,  8.31521079e-02,\n",
      "         2.10619569e-01, -2.32874870e-01,  9.11981463e-01,\n",
      "         2.67048299e-01, -1.76435277e-01,  3.66098523e-01],\n",
      "       [ 4.23231488e-03,  2.55345507e-03, -1.56905144e-01,\n",
      "        -2.83288630e-03,  4.52545248e-02, -6.99305981e-02,\n",
      "        -2.52695344e-02,  2.99679255e-03, -1.30810682e-02,\n",
      "         6.65945038e-02, -2.34326767e-03,  5.57386912e-02,\n",
      "        -1.75957810e-02, -1.02022901e-01, -2.38599489e-03,\n",
      "         7.88431894e-03,  4.85939197e-02, -4.44670580e-03,\n",
      "         5.88098839e-02,  4.62005958e-02,  5.95070771e-04,\n",
      "        -7.93279056e-03, -2.53461242e-01, -2.99964622e-02,\n",
      "        -3.27011570e-03, -5.48833050e-02, -5.23463152e-02,\n",
      "        -2.84245878e-04,  1.01732940e-03,  3.02496552e-01,\n",
      "        -9.12591524e-04, -3.90170462e-04, -1.31679654e-01,\n",
      "        -2.63096439e-03, -5.03516197e-02,  5.19864843e-05,\n",
      "        -6.62574470e-02,  2.66578491e-03,  1.57256064e-03,\n",
      "        -1.40791582e-02,  1.13087408e-01,  1.60000071e-01,\n",
      "        -6.76322103e-01, -5.86312190e-02,  7.21174777e-01,\n",
      "        -8.41963068e-02,  3.72799672e-02, -2.08762065e-01,\n",
      "        -5.48128188e-01, -4.35538255e-02,  4.58081335e-01,\n",
      "         6.61157668e-02, -4.77108747e-01,  5.37105024e-01,\n",
      "        -2.11007595e-01,  1.16080500e-01, -1.79704070e-01,\n",
      "        -2.94251382e-01,  3.10811579e-01, -2.95215786e-01],\n",
      "       [ 2.31614313e-03,  2.70848675e-03,  6.17985874e-02,\n",
      "        -4.18302342e-02, -3.62961516e-02, -3.08660746e-01,\n",
      "        -1.26086578e-01,  1.88824728e-01, -2.04411969e-02,\n",
      "        -2.21692353e-01,  8.66987370e-03,  5.33445515e-02,\n",
      "        -3.16416994e-02, -6.00561015e-02,  1.02106780e-01,\n",
      "         4.84122932e-01,  3.22539270e-01,  2.35186845e-01,\n",
      "         1.44535393e-01,  1.52301481e-02,  2.06084922e-03,\n",
      "        -1.06680840e-01, -1.06378980e-01, -3.34576500e-04,\n",
      "         5.79986768e-03, -4.10322905e-01, -9.96128395e-02,\n",
      "         4.67344071e-05,  4.24623080e-02,  5.65330684e-02,\n",
      "        -6.91223249e-04, -5.48742944e-03, -2.54441828e-01,\n",
      "        -3.47621217e-02, -6.43719435e-02, -5.08272424e-02,\n",
      "        -4.79770340e-02, -1.55176118e-03, -9.73723945e-05,\n",
      "        -1.02779076e-01, -5.87618686e-02,  3.74834269e-01,\n",
      "        -4.09632504e-01, -3.51621807e-01,  1.60704121e-01,\n",
      "        -3.33539754e-01, -6.37862444e-01,  6.56806350e-01,\n",
      "         3.39614630e-01,  3.17443222e-01, -1.13149315e-01,\n",
      "        -4.83597934e-01, -7.39004433e-01, -7.69932449e-01,\n",
      "         6.38211250e-01,  3.47542554e-01,  3.19252163e-01,\n",
      "        -1.41536608e-01,  4.12308633e-01, -3.46735239e-01],\n",
      "       [ 1.98997150e-04,  2.81740795e-05, -1.08802319e-03,\n",
      "        -2.20606732e-03,  1.45928678e-03, -1.03822248e-02,\n",
      "        -4.79037827e-03, -3.65357334e-03, -3.12620797e-03,\n",
      "         3.25210392e-03,  3.22286010e-04, -1.72921136e-05,\n",
      "        -1.00943420e-04,  7.34257745e-04,  1.06379222e-02,\n",
      "        -7.98176825e-02,  7.69575359e-04,  2.73426771e-02,\n",
      "         1.98771991e-03, -7.44388846e-04,  1.40256539e-03,\n",
      "        -2.09748745e-04, -3.16454098e-04,  9.96410148e-04,\n",
      "        -1.09091366e-03, -8.60737115e-02,  6.83279824e-04,\n",
      "        -7.25646736e-04, -5.56164421e-04,  8.39150324e-03,\n",
      "        -1.22563192e-03, -3.77875869e-04,  2.25918810e-03,\n",
      "         2.44814117e-04,  1.15580077e-03,  1.14230544e-03,\n",
      "        -2.72679329e-03,  3.69357731e-04, -2.13795807e-03,\n",
      "        -1.33185997e-04, -1.31450757e-01, -4.05867338e-01,\n",
      "         1.66488335e-01,  4.41891730e-01, -6.76590979e-01,\n",
      "        -7.30694115e-01,  5.34745336e-01,  1.62607175e-03,\n",
      "         2.84012780e-03,  5.78940988e-01,  9.73462880e-01,\n",
      "         9.28247813e-03,  3.94374013e-01,  2.03803524e-01,\n",
      "         3.34620804e-01, -6.57359183e-01,  5.22522092e-01,\n",
      "         4.08485621e-01,  2.31990945e-02,  7.05946147e-01],\n",
      "       [-3.56671197e-04, -5.51942503e-04, -4.16804990e-03,\n",
      "        -1.01806119e-03,  4.44242032e-04, -3.11905652e-01,\n",
      "         1.17159181e-03, -2.61246134e-02,  5.05821817e-02,\n",
      "        -1.79872617e-01, -2.02328665e-04, -4.59375326e-03,\n",
      "         1.00235967e-03,  6.05200068e-04, -8.32888181e-04,\n",
      "        -2.47949436e-02, -1.17312044e-01, -1.47479202e-03,\n",
      "         5.08006837e-04,  1.96286710e-04, -1.62166613e-03,\n",
      "         1.83315184e-02,  7.53172964e-04, -3.56084178e-03,\n",
      "        -1.67960720e-03, -1.23675935e-01, -3.31329531e-04,\n",
      "        -4.42354847e-03, -1.29633269e-03,  3.86499363e-04,\n",
      "        -5.37575979e-04,  4.05772007e-04, -1.81693956e-02,\n",
      "        -3.00468761e-03,  8.70148506e-06, -8.73949006e-03,\n",
      "        -2.91158329e-04,  5.59714623e-03,  8.08321274e-05,\n",
      "         1.17018753e-04,  2.91598827e-01, -1.58212733e+00,\n",
      "         6.48576200e-01, -5.02723753e-01, -1.89958841e-01,\n",
      "        -7.86604464e-01, -3.65119934e-01, -5.60077012e-01,\n",
      "        -2.02246651e-01,  9.03440595e-01,  1.44101962e-01,\n",
      "         2.87312213e-02, -2.33273223e-01, -2.45107681e-01,\n",
      "        -1.37505019e+00, -1.50622571e+00,  1.36642724e-01,\n",
      "        -1.35593152e+00, -2.30473606e-03,  5.39892018e-01],\n",
      "       [ 2.29148747e-04,  4.72770398e-03,  1.55850025e-02,\n",
      "        -6.39792625e-03, -6.38683152e-04, -5.48522687e-03,\n",
      "        -1.38901070e-01, -1.01784930e-01,  5.12590446e-02,\n",
      "         1.53342590e-01,  1.28022293e-02,  7.43647888e-02,\n",
      "        -1.00188643e-01, -1.21250592e-01, -2.46175216e-03,\n",
      "        -3.71099710e-02,  1.40275687e-01, -3.89328897e-02,\n",
      "         1.46665365e-01,  6.22828864e-02,  4.71975561e-03,\n",
      "        -3.27972993e-02, -3.04090296e-04, -2.80445796e-02,\n",
      "        -1.77962612e-03,  1.14027627e-01, -1.07692078e-01,\n",
      "         4.37476393e-03,  4.20469046e-03,  5.08782685e-01,\n",
      "        -3.12532089e-03, -2.22561182e-03, -3.16723228e-01,\n",
      "        -1.87083054e-02, -1.06733367e-01,  1.70641676e-01,\n",
      "        -4.59822342e-02, -1.09152058e-02,  6.00457331e-03,\n",
      "        -1.23125352e-01,  7.53620565e-02, -3.06135237e-01,\n",
      "         8.50763842e-02, -2.44487766e-02,  3.53273273e-01,\n",
      "         7.82866701e-02,  3.49891990e-01,  1.25401706e-01,\n",
      "        -1.72823310e-01, -5.69317341e-01,  3.34950797e-02,\n",
      "         3.78031701e-01,  3.31572026e-01, -3.56156260e-01,\n",
      "        -4.04327631e-01, -2.26045474e-01,  2.93256432e-01,\n",
      "         6.57124877e-01, -2.14313775e-01,  6.21473908e-01]], dtype=float32), array([[ 0.2547662 , -1.5956873 ,  0.5381945 , ..., -0.04540122,\n",
      "        -0.17521429,  0.09907386],\n",
      "       [-0.1972358 ,  0.40938932, -0.10172142, ..., -0.02591249,\n",
      "         0.05612437, -0.01706762],\n",
      "       [ 0.1131779 ,  0.5642235 , -0.6361113 , ...,  0.12777792,\n",
      "         0.01741279, -0.08060289],\n",
      "       ...,\n",
      "       [ 0.40027168, -2.0197344 , -0.04204833, ...,  0.3667501 ,\n",
      "         0.28856075, -0.290329  ],\n",
      "       [-0.29717204, -1.2852434 ,  1.0112786 , ...,  0.13798244,\n",
      "        -0.1433113 ,  0.07184523],\n",
      "       [ 0.00637636, -1.1120826 ,  0.2884464 , ..., -0.21668996,\n",
      "         0.37578803,  0.03763884]], dtype=float32), array([[ 2.81436086e-01, -5.76437175e-01,  2.32842311e-01,\n",
      "        -1.64791986e-01,  2.18204632e-01, -4.69416380e-02,\n",
      "         6.05323799e-02,  3.17433804e-01,  5.14878273e-01,\n",
      "         9.42288041e-02,  2.25569412e-01,  2.20912650e-01,\n",
      "        -3.04075480e-01, -5.68693399e-01, -4.12724912e-01,\n",
      "         8.66159722e-02,  1.22743346e-01, -3.39279026e-01,\n",
      "         2.19026417e-01,  5.33570722e-02, -6.20024018e-02,\n",
      "        -5.73013909e-02,  4.51232269e-02,  3.91284935e-02,\n",
      "         1.06005915e-01, -1.99087448e-02, -6.02101237e-02,\n",
      "         7.22390264e-02,  1.85252756e-01,  6.07409254e-02,\n",
      "         4.20395583e-01,  3.73291850e-01,  7.59343132e-02,\n",
      "         2.66408801e-01, -1.85843706e-01,  8.52836594e-02,\n",
      "        -1.28108799e-01, -6.39122948e-02,  2.86752373e-01,\n",
      "        -5.81026189e-02, -3.92567143e-02,  2.64287777e-02,\n",
      "         7.63755515e-02,  7.58185685e-02, -7.99669549e-02,\n",
      "         2.48397775e-02, -2.02453081e-02, -1.52606785e-01,\n",
      "         6.90286607e-02, -8.20673723e-03, -6.47843555e-02,\n",
      "         1.03125088e-02,  1.51631817e-01,  2.16561288e-01,\n",
      "        -9.75761935e-03, -4.33867313e-02, -2.38770135e-02,\n",
      "        -6.44564033e-02,  3.02510317e-02, -1.53629435e-02],\n",
      "       [ 2.81436086e-01, -5.76437175e-01,  2.32842311e-01,\n",
      "        -1.64791986e-01,  2.18204632e-01, -4.69416380e-02,\n",
      "         6.05323799e-02,  3.17433804e-01,  5.14878273e-01,\n",
      "         9.42288041e-02,  2.25569412e-01,  2.20912650e-01,\n",
      "        -3.04075480e-01, -5.68693399e-01, -4.12724912e-01,\n",
      "         8.66159722e-02,  1.22743346e-01, -3.39279026e-01,\n",
      "         2.19026417e-01,  5.33570722e-02, -6.20024018e-02,\n",
      "        -5.73013909e-02,  4.51232269e-02,  3.91284935e-02,\n",
      "         1.06005915e-01, -1.99087448e-02, -6.02101237e-02,\n",
      "         7.22390264e-02,  1.85252756e-01,  6.07409254e-02,\n",
      "         4.20395583e-01,  3.73291850e-01,  7.59343132e-02,\n",
      "         2.66408801e-01, -1.85843706e-01,  8.52836594e-02,\n",
      "        -1.28108799e-01, -6.39122948e-02,  2.86752373e-01,\n",
      "        -5.81026189e-02, -2.81387437e-02,  2.68114358e-02,\n",
      "         6.96840510e-02,  6.70198798e-02, -7.70879388e-02,\n",
      "         4.44244072e-02, -2.28664782e-02, -1.34402499e-01,\n",
      "         7.29346350e-02, -2.84571979e-05, -6.88853040e-02,\n",
      "         4.09746654e-02,  2.42096901e-01,  2.12893099e-01,\n",
      "        -1.68867111e-02, -3.82843018e-02, -3.61209698e-02,\n",
      "        -4.52901572e-02,  1.60063393e-02, -2.93352641e-02]], dtype=float32)]\n",
      "layer3 [array([[ 0.01229447, -0.22324923,  0.19501397, ..., -0.17184433,\n",
      "         0.21908292,  0.14177498],\n",
      "       [ 0.11673367, -0.09635278,  0.21111059, ...,  0.09613656,\n",
      "        -0.00978793,  0.4755055 ],\n",
      "       [ 0.009658  , -0.10858133, -0.13214962, ..., -0.4156584 ,\n",
      "         0.28413576,  0.03586777],\n",
      "       ...,\n",
      "       [ 0.35911855,  0.02502975, -0.19156286, ..., -0.36926734,\n",
      "         0.0074881 ,  0.00370959],\n",
      "       [ 0.14823784, -0.27106306,  0.04552089, ..., -0.09356158,\n",
      "         0.0053038 ,  0.37636766],\n",
      "       [-0.20516506,  0.06978884,  0.16070245, ..., -0.08034292,\n",
      "         0.21738967,  0.02353435]], dtype=float32), array([ 1.00152470e-01, -1.52927890e-01,  6.07248507e-02,  1.96647301e-01,\n",
      "        6.14593811e-02,  7.60432556e-02,  6.97721541e-02,  1.89560279e-02,\n",
      "       -3.36471348e-05, -1.30891308e-01, -8.09587240e-02, -5.83618432e-02,\n",
      "        2.07990706e-01,  1.54156670e-01,  6.67909607e-02,  2.39230972e-02,\n",
      "        1.00770205e-01,  9.84800011e-02,  8.12115073e-02, -3.16481926e-02,\n",
      "       -2.75552541e-01,  1.47427127e-01, -5.97458258e-02,  1.23067079e-02,\n",
      "       -4.88053784e-02,  9.22545195e-02,  1.28791526e-01, -3.71264182e-02,\n",
      "       -2.30013862e-01,  1.12804949e-01,  1.29991740e-01,  4.45802473e-02,\n",
      "       -1.51350513e-01,  1.14446744e-01, -5.74461930e-02, -8.49256739e-02,\n",
      "       -1.36569247e-01,  3.09964269e-02,  2.89026946e-01, -1.15912631e-01,\n",
      "        8.15137401e-02,  3.92270796e-02,  1.34328187e-01, -1.89812630e-01,\n",
      "        7.67239928e-02,  7.30310800e-03, -4.00884487e-02,  1.47168458e-01,\n",
      "        8.76639038e-02,  1.32547602e-01, -5.24970796e-03,  1.10786408e-01,\n",
      "       -1.68056697e-01, -3.82301281e-03, -1.71430275e-01, -2.02732474e-01,\n",
      "        1.36155397e-01,  2.23872110e-01, -1.31419286e-01, -1.15223259e-01,\n",
      "        4.97484803e-02, -8.24902281e-02,  1.79026529e-01,  1.20720573e-01],\n",
      "      dtype=float32)]\n",
      "relu_0 []\n",
      "output_sigmoid [array([[-0.24244325],\n",
      "       [ 0.09209516],\n",
      "       [ 0.4713707 ],\n",
      "       [-0.34837243],\n",
      "       [ 0.09008387],\n",
      "       [-0.4321378 ],\n",
      "       [-0.4196793 ],\n",
      "       [ 0.36432227],\n",
      "       [-0.251564  ],\n",
      "       [-0.48966372],\n",
      "       [-0.5312869 ],\n",
      "       [-1.1740428 ],\n",
      "       [-0.4015674 ],\n",
      "       [-1.4949555 ],\n",
      "       [-0.5092534 ],\n",
      "       [ 0.26210952],\n",
      "       [-0.3193608 ],\n",
      "       [-0.3885873 ],\n",
      "       [-0.44647008],\n",
      "       [ 0.86457837],\n",
      "       [ 2.2733119 ],\n",
      "       [ 1.915615  ],\n",
      "       [ 0.205332  ],\n",
      "       [ 0.36153185],\n",
      "       [ 0.26309344],\n",
      "       [ 0.27137357],\n",
      "       [ 0.2683873 ],\n",
      "       [ 3.4658053 ],\n",
      "       [-1.2390317 ],\n",
      "       [-1.7519488 ],\n",
      "       [-0.4866012 ],\n",
      "       [ 0.26820016],\n",
      "       [-1.682128  ],\n",
      "       [-0.3732701 ],\n",
      "       [ 0.11305073],\n",
      "       [ 0.11105518],\n",
      "       [-0.44706324],\n",
      "       [-0.42661926],\n",
      "       [-0.6895412 ],\n",
      "       [-1.755053  ],\n",
      "       [ 0.4246848 ],\n",
      "       [-1.1487931 ],\n",
      "       [ 0.52523583],\n",
      "       [-1.1501548 ],\n",
      "       [ 0.5277986 ],\n",
      "       [ 0.39119828],\n",
      "       [ 0.14759196],\n",
      "       [-0.62216365],\n",
      "       [ 0.45277154],\n",
      "       [ 0.5815481 ],\n",
      "       [ 1.2075722 ],\n",
      "       [ 0.34938216],\n",
      "       [ 0.38497293],\n",
      "       [-0.33411583],\n",
      "       [-0.53848976],\n",
      "       [-0.9948236 ],\n",
      "       [-0.64951044],\n",
      "       [ 1.5989385 ],\n",
      "       [ 0.14653887],\n",
      "       [ 0.21397543],\n",
      "       [ 0.46299803],\n",
      "       [ 0.76180345],\n",
      "       [-0.31727275],\n",
      "       [-0.6014883 ]], dtype=float32), array([0.00909589], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "gru = load_model('gru/model_gru.h5')\n",
    "for layer in gru.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db297db7",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9865afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (LSTM)               (None, 20)                2160      \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 64)                1344      \n",
      "                                                                 \n",
      " output_sigmoid (Dense)      (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,569\n",
      "Trainable params: 3,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, kernel_initializer = 'VarianceScaling', kernel_regularizer = regularizers.l1_l2(l1= 0.00001, l2 = 0.0001),\n",
    "               name = 'layer1', input_shape = (20,6)))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_normal', name='layer3'))\n",
    "model.add(Dense(1, activation='sigmoid', name = 'output_sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=150)\n",
    "adam = Adam(lr = 0.0002)\n",
    "    \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 256,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint(f'lstm/model_lstm.h5', verbose=1, save_best_only=True), es],\n",
    "                    use_multiprocessing=True, workers=4)\n",
    "labels = ['j_t']\n",
    "y_keras = model.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(auc_score)\n",
    "\n",
    "# print(history.history.keys())\n",
    "#     # summarize history for accuracy\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# print(history.history.keys())\n",
    "#     # summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5e8ed",
   "metadata": {},
   "source": [
    "## LSTM weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7c5afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 [array([[ 7.39419879e-03, -5.83838159e-03,  3.01538318e-01,\n",
      "         1.71923459e-01,  6.68122293e-03,  2.97626834e-02,\n",
      "         3.32187265e-01,  1.97732152e-04, -2.47867294e-02,\n",
      "        -2.70899326e-01,  2.38649055e-01, -1.53928593e-01,\n",
      "        -2.45593235e-01, -4.70351195e-03, -4.40326781e-04,\n",
      "        -9.93248895e-02, -4.17812057e-02,  1.16892830e-02,\n",
      "         3.17993254e-05, -1.51097625e-01,  1.57310724e-01,\n",
      "         3.35737281e-02,  1.41706407e-01, -2.90701236e-03,\n",
      "        -1.97995920e-03, -2.25614622e-01, -1.60605669e-01,\n",
      "         4.88352962e-04, -7.87862241e-02,  1.11477904e-01,\n",
      "        -2.62344658e-01, -4.76501277e-03, -1.96079127e-02,\n",
      "        -1.55211061e-01,  4.44040663e-04, -2.17573345e-02,\n",
      "        -1.32157400e-01,  3.02360058e-02,  1.89535355e-03,\n",
      "         1.29000042e-02,  1.78925186e-01,  1.04064144e-01,\n",
      "         4.50133756e-02,  3.35197598e-01,  7.82899320e-01,\n",
      "        -6.99297264e-02, -2.05348253e-01,  4.42941576e-01,\n",
      "         5.70073307e-01,  1.53039768e-01, -3.16302985e-01,\n",
      "        -5.73586207e-04, -3.13368410e-01, -4.53246236e-02,\n",
      "        -1.13448434e-01,  3.21308263e-02,  3.35050970e-01,\n",
      "        -4.30386156e-01, -8.23351666e-02,  4.66400385e-01,\n",
      "         3.32129630e-03, -5.07687211e-01, -3.40431035e-02,\n",
      "        -7.52600143e-04, -1.56125089e-03, -2.92731375e-02,\n",
      "        -6.16987795e-02,  6.95518829e-05, -3.99682671e-01,\n",
      "        -1.84742942e-01,  1.64073408e-01, -4.30221468e-01,\n",
      "        -2.24486768e-01, -9.14868489e-02,  2.58685963e-04,\n",
      "        -6.14800230e-02, -5.00882752e-02,  4.40536328e-02,\n",
      "        -6.93644106e-04,  7.34629761e-03],\n",
      "       [-3.28716129e-01, -2.44900092e-01,  5.46452701e-01,\n",
      "        -3.58948857e-01, -3.35916102e-01, -2.38378495e-01,\n",
      "         1.72986835e-01,  7.02163801e-02,  2.00826734e-01,\n",
      "        -1.15829058e-01,  3.44162458e-03, -7.85224959e-02,\n",
      "        -1.09239750e-01,  4.10475463e-01,  1.45637197e-02,\n",
      "        -6.57098651e-01, -2.20853657e-01,  1.03420407e-01,\n",
      "         1.77041456e-01,  3.50637347e-01, -5.91466367e-01,\n",
      "         3.25459570e-01,  3.83389831e-01, -2.73216605e-01,\n",
      "         3.12409401e-01, -8.78353976e-03,  4.73820895e-01,\n",
      "         2.84132749e-01, -2.45404020e-01, -4.89488477e-03,\n",
      "        -3.89132649e-01,  1.91164359e-01, -3.10424626e-01,\n",
      "        -1.44695058e-01,  2.72645839e-02,  3.27662677e-01,\n",
      "         2.02122912e-01,  4.67433259e-02, -2.12500710e-02,\n",
      "        -9.65390205e-02,  4.65540200e-01, -3.43191177e-01,\n",
      "        -1.59871891e-01, -4.29165542e-01,  8.48131478e-01,\n",
      "        -3.41020882e-01, -2.53186017e-01, -4.19941485e-01,\n",
      "         5.28918207e-01,  5.82442462e-01,  2.43787318e-01,\n",
      "        -2.27818042e-01,  4.26677704e-01, -1.98188812e-01,\n",
      "        -4.84601438e-01, -4.33058918e-01, -2.74777383e-01,\n",
      "        -1.21734984e-01, -3.43523145e-01, -8.16515163e-02,\n",
      "         5.87399602e-01, -8.98978040e-02, -3.07960927e-01,\n",
      "         5.80000818e-01,  1.28900260e-01, -1.08914845e-01,\n",
      "        -6.29972592e-02,  2.31626406e-01, -1.90226763e-01,\n",
      "        -5.50031066e-01, -3.10535222e-01, -5.41547954e-01,\n",
      "         6.43718541e-02, -5.64934537e-02, -5.29288985e-02,\n",
      "         1.87875420e-01,  4.02700424e-01,  5.38922608e-01,\n",
      "        -7.28375604e-03, -1.59341201e-01],\n",
      "       [ 1.60526648e-01, -5.08656740e-01,  4.91059780e-01,\n",
      "        -5.08043058e-02,  1.66007876e-01,  4.38902080e-01,\n",
      "        -2.27305800e-01, -1.51988283e-01,  5.82895517e-01,\n",
      "        -6.90359890e-01,  6.24397397e-01,  2.90788332e-04,\n",
      "        -1.77537352e-01, -3.33005264e-02,  4.05488402e-01,\n",
      "         2.55914062e-01,  6.79085851e-01,  6.90969527e-01,\n",
      "        -1.60890371e-01, -1.73719972e-01,  5.52013218e-01,\n",
      "         1.69739425e-01, -1.24109000e-01,  6.14493750e-02,\n",
      "        -1.46662429e-01, -6.22962415e-01,  2.75146872e-01,\n",
      "        -6.17038980e-02,  5.71272552e-01,  3.07869017e-01,\n",
      "         2.78320938e-01,  2.01456830e-01,  1.64522320e-01,\n",
      "         6.47316873e-01,  3.35304858e-03, -3.13390970e-01,\n",
      "         7.06626654e-01,  3.02585244e-01,  2.53136992e-01,\n",
      "        -2.05151349e-01, -5.61803520e-01, -1.75928727e-01,\n",
      "        -6.48213744e-01,  1.70157060e-01, -2.83245116e-01,\n",
      "        -3.29614669e-01, -5.68819642e-01, -2.21783802e-01,\n",
      "        -4.89702635e-02, -6.12870269e-02, -8.69671851e-02,\n",
      "         5.84267788e-02,  1.52703533e-02,  1.85983345e-01,\n",
      "         4.02484179e-01, -4.42521155e-01,  3.36662292e-01,\n",
      "         3.32728505e-01,  1.20028272e-01,  2.42570311e-01,\n",
      "         5.48762321e-01, -4.28260356e-01,  2.94502079e-01,\n",
      "        -4.71368767e-02, -7.59690404e-02,  1.67899892e-01,\n",
      "        -2.92049527e-01, -2.75961429e-01,  1.01516858e-01,\n",
      "        -4.53550220e-01, -5.21407902e-01, -7.37025857e-01,\n",
      "        -1.01022676e-01,  4.84473050e-01, -2.25554034e-01,\n",
      "        -6.42343983e-03, -3.10420662e-01,  4.66528296e-01,\n",
      "         7.61529580e-02,  2.86702573e-01],\n",
      "       [ 2.66415477e-01,  8.93055089e-03,  1.68879777e-01,\n",
      "        -2.24934635e-03,  6.07293705e-03,  1.13566741e-02,\n",
      "        -1.77582398e-01,  1.75580833e-04,  1.11894147e-03,\n",
      "        -6.07022606e-02,  6.40261322e-02, -1.09365106e-01,\n",
      "        -3.33885133e-01, -2.70901807e-02, -4.23467543e-04,\n",
      "        -1.19119473e-01, -2.17101559e-01, -1.47045463e-01,\n",
      "        -2.66594754e-04, -8.20673257e-02,  1.61730543e-01,\n",
      "        -1.74233951e-02,  2.10965928e-02, -1.44373449e-02,\n",
      "         3.12090293e-02, -3.74311954e-02, -9.11211973e-05,\n",
      "         5.02448238e-04, -7.47069120e-02,  2.54624128e-01,\n",
      "        -1.23740628e-01, -4.57032677e-03,  2.09506318e-01,\n",
      "         5.28994262e-01,  4.46075661e-04, -1.45829786e-02,\n",
      "        -5.87239005e-02,  5.47579955e-03,  1.64525036e-03,\n",
      "         1.71495900e-02,  7.25281537e-02, -6.36460900e-01,\n",
      "        -4.19682384e-01, -5.01603544e-01,  5.48103213e-01,\n",
      "         2.36143842e-01,  3.01123573e-03,  1.11150712e-01,\n",
      "        -3.90604675e-01, -7.15175688e-01, -1.08803026e-01,\n",
      "         6.07226975e-02, -7.30009735e-01,  4.57354933e-01,\n",
      "        -4.50189859e-01,  3.44043791e-01,  1.64497420e-01,\n",
      "        -1.16725125e-04, -3.65595594e-02,  7.50012994e-01,\n",
      "         5.12369350e-02,  2.07667857e-01,  4.54063751e-02,\n",
      "        -2.97826808e-02,  5.05907834e-03, -2.67768174e-01,\n",
      "         8.24314207e-02, -3.21510038e-03, -2.04321414e-01,\n",
      "         2.10767150e-01,  4.06967551e-01, -6.72989607e-01,\n",
      "        -5.96767187e-01, -1.11987432e-02,  2.35089508e-04,\n",
      "        -2.96711959e-02,  3.37040387e-02,  5.15699834e-02,\n",
      "        -1.00249005e-03,  1.55598998e-01],\n",
      "       [ 8.61639436e-03,  4.99923974e-02,  1.22815827e-02,\n",
      "        -8.23966227e-03, -4.65040021e-02, -1.63783148e-01,\n",
      "         1.03772327e-01, -3.95936804e-05, -9.54395253e-03,\n",
      "         2.08970711e-01, -7.08470792e-02,  4.96865064e-03,\n",
      "         2.13763699e-01, -1.34257041e-03,  3.75835947e-03,\n",
      "        -1.63020811e-03,  3.60732645e-01, -8.96815956e-02,\n",
      "         3.50422633e-04, -3.17975064e-04,  1.79202724e-02,\n",
      "         7.15256631e-02, -1.30170481e-02, -9.42516699e-03,\n",
      "        -5.52215381e-03, -2.59293497e-01,  7.84747452e-02,\n",
      "         2.87224539e-05, -8.30676183e-02,  6.86437115e-02,\n",
      "        -1.38661444e-01, -1.06992235e-03, -1.30785890e-02,\n",
      "        -1.57720074e-01,  3.15012853e-03, -8.45961913e-04,\n",
      "        -8.19899607e-03, -1.11454599e-01,  4.10139142e-03,\n",
      "         1.82157150e-03,  7.26869881e-01, -2.97495484e-01,\n",
      "         8.81257772e-01,  5.11263847e-01, -1.35321349e-01,\n",
      "         1.16809167e-01, -2.51141079e-02, -4.52054571e-03,\n",
      "        -6.71572268e-01,  1.75425977e-01,  3.59781981e-01,\n",
      "        -7.80885220e-02, -7.17577159e-01, -1.05831456e+00,\n",
      "         1.04923910e-02,  3.19806188e-02,  8.40756476e-01,\n",
      "        -9.14865792e-01,  2.33968839e-01, -1.03071535e+00,\n",
      "         2.82586478e-02,  5.79244271e-02,  2.08772160e-03,\n",
      "         4.96676425e-04, -5.89613896e-03, -5.48035912e-02,\n",
      "         5.55179000e-01, -4.84706834e-05, -1.04495972e-01,\n",
      "         1.46320596e-01, -1.15830056e-01,  1.42132849e-01,\n",
      "         2.23197460e-01, -1.15714194e-02,  4.19469364e-03,\n",
      "        -1.17815391e-03,  7.80695081e-02, -7.66332448e-02,\n",
      "         1.39388256e-03, -2.14353623e-03],\n",
      "       [-4.07934844e-01, -1.13039620e-01,  2.64513135e-01,\n",
      "        -4.38021243e-01,  3.35002005e-01, -4.12003130e-01,\n",
      "         4.35206413e-01,  2.97860950e-01, -3.78114320e-02,\n",
      "         3.34902734e-01,  1.29939793e-02, -2.79776812e-01,\n",
      "         8.98513943e-02, -2.60842610e-02, -1.70483887e-01,\n",
      "        -6.95443630e-01,  6.64738536e-01,  6.22227728e-01,\n",
      "         2.71683093e-02,  3.26725572e-01, -6.00026399e-02,\n",
      "         4.75720495e-01, -2.76030209e-02,  8.83233920e-02,\n",
      "        -5.37337244e-01, -7.48510659e-01,  4.58738804e-02,\n",
      "        -3.78286481e-01,  1.25653967e-01, -3.79419029e-02,\n",
      "         2.26743966e-01,  2.03513533e-01, -5.02456486e-01,\n",
      "        -9.27537121e-03,  2.83963829e-01, -6.24114513e-01,\n",
      "        -5.74134350e-01,  3.48448902e-01,  9.52991545e-02,\n",
      "         4.97220099e-01,  3.90240759e-01,  1.73828378e-01,\n",
      "         4.09691244e-01,  1.65374354e-01, -3.88504088e-01,\n",
      "        -1.73541814e-01, -4.88503397e-01,  3.51718739e-02,\n",
      "        -3.92605096e-01,  5.24524033e-01, -5.15031934e-01,\n",
      "        -6.35197461e-01, -5.63825190e-01,  2.80027986e-01,\n",
      "         1.34824486e-02,  1.92983329e-01, -3.12184274e-01,\n",
      "         1.08689982e-02,  9.44670886e-02, -2.07321987e-01,\n",
      "         2.87961781e-01, -2.54605711e-02,  2.39608020e-01,\n",
      "         1.34969756e-01,  3.51633765e-02, -3.77689481e-01,\n",
      "         4.04702991e-01, -4.64884102e-01,  4.39068079e-01,\n",
      "         1.49129732e-02, -1.88495681e-01, -8.45236257e-02,\n",
      "        -3.52230936e-01, -6.38642088e-02,  3.85615498e-01,\n",
      "        -1.11426093e-01,  2.91014731e-01,  4.97033000e-01,\n",
      "         1.30584445e-02,  1.80587053e-01]], dtype=float32), array([[ 0.29212976,  0.04304757,  0.03014837, ...,  0.0954902 ,\n",
      "         0.16338478,  0.13998054],\n",
      "       [-0.30484933, -0.01881308, -0.03267962, ..., -0.01865025,\n",
      "        -0.0984621 , -0.48621187],\n",
      "       [ 0.03106425, -0.05314958, -0.12408169, ..., -0.08263548,\n",
      "        -0.1282424 , -0.32344285],\n",
      "       ...,\n",
      "       [-0.01131889, -0.1025546 ,  0.03702123, ...,  0.30089077,\n",
      "        -0.16501302, -0.13816522],\n",
      "       [ 0.22024494, -0.04513496,  0.12371146, ...,  0.04080974,\n",
      "         0.09322671,  0.00725434],\n",
      "       [ 0.3760036 , -0.34823954,  0.03966065, ...,  0.17483723,\n",
      "        -0.21940151, -0.18638289]], dtype=float32), array([ 8.41521025e-02, -1.92089230e-02,  1.98813505e-03,  4.14534584e-02,\n",
      "        5.63527904e-02, -1.09983832e-02, -2.46038921e-02, -2.20687073e-02,\n",
      "        1.81012470e-02,  8.76607839e-03, -7.83699304e-02,  8.08481313e-03,\n",
      "        1.06858671e-01,  1.20922171e-01, -1.00809686e-01, -4.97145690e-02,\n",
      "       -7.57661089e-02,  6.65638074e-02,  9.06718448e-02,  1.74166486e-01,\n",
      "        1.10181344e+00,  9.82022226e-01,  1.00313914e+00,  1.04298854e+00,\n",
      "        1.03888047e+00,  9.95821595e-01,  9.85188663e-01,  9.49392259e-01,\n",
      "        1.02625585e+00,  1.01973701e+00,  9.43433642e-01,  1.18140650e+00,\n",
      "        1.07742023e+00,  1.08097112e+00,  9.91087496e-01,  9.66635048e-01,\n",
      "        1.04673409e+00,  1.11440873e+00,  1.18411767e+00,  1.09430194e+00,\n",
      "        2.12009545e-05,  3.14482045e-03,  5.53223118e-02,  1.04024783e-02,\n",
      "       -4.29832824e-02,  2.43990403e-02, -1.04558524e-02,  5.34911007e-02,\n",
      "        9.67193116e-03,  5.11964262e-02,  2.94289943e-02, -1.12663962e-01,\n",
      "       -5.27811190e-03, -2.74686683e-02,  2.45666746e-02,  9.34261009e-02,\n",
      "       -1.20100453e-02, -1.34369927e-02, -2.99678855e-02, -2.53653508e-02,\n",
      "        8.98798928e-02, -1.01365233e-02,  1.63657274e-02,  4.91859019e-02,\n",
      "        1.34470522e-01, -1.01886010e-02,  4.93654050e-04, -2.50163749e-02,\n",
      "        1.05992174e-02, -1.12680783e-02, -4.55508791e-02,  6.77964687e-02,\n",
      "        9.76319313e-02,  1.06203347e-01, -1.22913904e-01, -4.48455997e-02,\n",
      "        1.82379946e-01,  1.03553437e-01,  9.49985608e-02,  2.74693340e-01],\n",
      "      dtype=float32)]\n",
      "layer3 [array([[ 0.25387213, -0.13233979,  0.03851437, ..., -0.0670336 ,\n",
      "        -0.29358572,  0.02626619],\n",
      "       [-0.01879188,  0.19864959,  0.00298953, ...,  0.00800291,\n",
      "        -0.31757322, -0.07833116],\n",
      "       [-0.31660467, -0.0194963 ,  0.13329142, ...,  0.18303378,\n",
      "        -0.09082277, -0.15082411],\n",
      "       ...,\n",
      "       [-0.18450558, -0.12703946,  0.18423139, ...,  0.01974635,\n",
      "         0.37216756, -0.26602164],\n",
      "       [-0.02679609, -0.0260149 , -0.14252757, ..., -0.00351013,\n",
      "        -0.10781524, -0.00530582],\n",
      "       [-0.13289176,  0.06902815, -0.07363845, ..., -0.06273006,\n",
      "         0.38545305,  0.10233137]], dtype=float32), array([ 0.02628169, -0.02139802, -0.04860304,  0.06219034,  0.01508032,\n",
      "       -0.03336877,  0.08691309, -0.11997601,  0.11585704, -0.03697913,\n",
      "        0.05671219, -0.04401666, -0.01937947, -0.0409448 ,  0.02808898,\n",
      "        0.12240782, -0.06257804, -0.01714978,  0.02892538,  0.05219321,\n",
      "        0.09880217,  0.05382546,  0.12147338,  0.02616763, -0.02021145,\n",
      "        0.00945206,  0.08222569,  0.1531212 ,  0.03555184,  0.10092333,\n",
      "        0.05496075,  0.05274351,  0.04131795,  0.09172414, -0.0461082 ,\n",
      "       -0.00547074, -0.09285305, -0.0463725 ,  0.04973523,  0.0726964 ,\n",
      "        0.04688222,  0.03390919,  0.0451732 , -0.06163898,  0.04029408,\n",
      "       -0.02756513,  0.0814473 ,  0.03284628,  0.07712383, -0.02733818,\n",
      "        0.0763882 , -0.07423645,  0.06898726,  0.01629847,  0.07236196,\n",
      "        0.02948867,  0.04031383,  0.03657626, -0.04361915,  0.06474742,\n",
      "        0.00282959, -0.03445014,  0.11221229,  0.03790955], dtype=float32)]\n",
      "output_sigmoid [array([[ 0.32569918],\n",
      "       [-0.21621843],\n",
      "       [ 0.12737395],\n",
      "       [-0.30582017],\n",
      "       [-0.1052185 ],\n",
      "       [ 0.18882781],\n",
      "       [-0.30654103],\n",
      "       [-0.503293  ],\n",
      "       [-0.41058597],\n",
      "       [-0.14233725],\n",
      "       [ 0.3052279 ],\n",
      "       [ 0.26672402],\n",
      "       [-0.69787824],\n",
      "       [ 0.00487436],\n",
      "       [ 0.23159991],\n",
      "       [-0.24363214],\n",
      "       [ 0.2635234 ],\n",
      "       [ 0.04026587],\n",
      "       [ 0.36191893],\n",
      "       [ 0.4421373 ],\n",
      "       [-0.5989848 ],\n",
      "       [-0.26102176],\n",
      "       [-0.40397984],\n",
      "       [ 0.39325243],\n",
      "       [ 0.0808723 ],\n",
      "       [-0.23699272],\n",
      "       [-0.4605558 ],\n",
      "       [-0.42996433],\n",
      "       [ 0.23651993],\n",
      "       [-0.2598254 ],\n",
      "       [-0.32432407],\n",
      "       [-0.1739983 ],\n",
      "       [-0.27926025],\n",
      "       [-0.22417226],\n",
      "       [ 0.12832335],\n",
      "       [ 0.09401517],\n",
      "       [ 0.05044727],\n",
      "       [ 0.11084021],\n",
      "       [-0.37676224],\n",
      "       [-0.42641842],\n",
      "       [-0.34499717],\n",
      "       [ 0.32799882],\n",
      "       [-0.39522007],\n",
      "       [ 0.19419019],\n",
      "       [-0.27361652],\n",
      "       [ 0.23239139],\n",
      "       [ 0.4759575 ],\n",
      "       [-0.39780217],\n",
      "       [-0.27441007],\n",
      "       [ 0.1962712 ],\n",
      "       [-0.28918427],\n",
      "       [-0.07462909],\n",
      "       [-0.2256864 ],\n",
      "       [-0.33376396],\n",
      "       [-0.37980372],\n",
      "       [ 0.433872  ],\n",
      "       [-0.3595942 ],\n",
      "       [ 0.30093986],\n",
      "       [ 0.12853254],\n",
      "       [-0.41600794],\n",
      "       [-0.07421066],\n",
      "       [-0.13473731],\n",
      "       [-0.3981971 ],\n",
      "       [ 0.34618548]], dtype=float32), array([0.00300966], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "lstm = load_model('lstm/model_toptag_lstm.h5')\n",
    "for layer in lstm.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9012a",
   "metadata": {},
   "source": [
    "## Quantization Aware Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56035701",
   "metadata": {},
   "source": [
    "## QGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315c062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (QGRU)               (None, 20)                1680      \n",
      "                                                                 \n",
      " layer3 (QDense)             (None, 64)                1344      \n",
      "                                                                 \n",
      " relu_0 (QActivation)        (None, 64)                0         \n",
      "                                                                 \n",
      " output_sigmoid (QDense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,089\n",
      "Trainable params: 3,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyihu\\anaconda3\\envs\\hls4ml-tutorial\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 2.2782 - accuracy: 0.5576\n",
      "Epoch 1: val_loss improved from inf to 3.56175, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 10s 287ms/step - loss: 2.2782 - accuracy: 0.5576 - val_loss: 3.5617 - val_accuracy: 0.5960\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 3.2003 - accuracy: 0.6003\n",
      "Epoch 2: val_loss improved from 3.56175 to 2.77085, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 154ms/step - loss: 3.2003 - accuracy: 0.6003 - val_loss: 2.7708 - val_accuracy: 0.6462\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 3.1697 - accuracy: 0.6375\n",
      "Epoch 3: val_loss improved from 2.77085 to 1.97440, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 3.1697 - accuracy: 0.6375 - val_loss: 1.9744 - val_accuracy: 0.6920\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 2.7138 - accuracy: 0.6562\n",
      "Epoch 4: val_loss did not improve from 1.97440\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 2.7138 - accuracy: 0.6562 - val_loss: 3.1118 - val_accuracy: 0.6781\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 2.2593 - accuracy: 0.6351\n",
      "Epoch 5: val_loss improved from 1.97440 to 1.32971, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 2.2593 - accuracy: 0.6351 - val_loss: 1.3297 - val_accuracy: 0.6225\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.9304 - accuracy: 0.6504\n",
      "Epoch 6: val_loss did not improve from 1.32971\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 1.9304 - accuracy: 0.6504 - val_loss: 1.5961 - val_accuracy: 0.6412\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.6154 - accuracy: 0.6279\n",
      "Epoch 7: val_loss improved from 1.32971 to 1.04872, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 152ms/step - loss: 1.6154 - accuracy: 0.6279 - val_loss: 1.0487 - val_accuracy: 0.6267\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.5013 - accuracy: 0.6567\n",
      "Epoch 8: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 1.5013 - accuracy: 0.6567 - val_loss: 1.0781 - val_accuracy: 0.6621\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.6804\n",
      "Epoch 9: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 1.5990 - accuracy: 0.6804 - val_loss: 1.4466 - val_accuracy: 0.7192\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.5577 - accuracy: 0.7220\n",
      "Epoch 10: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 1.5577 - accuracy: 0.7220 - val_loss: 1.2686 - val_accuracy: 0.7278\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.6259 - accuracy: 0.7157\n",
      "Epoch 11: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 1.6259 - accuracy: 0.7157 - val_loss: 1.2722 - val_accuracy: 0.7288\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.3859 - accuracy: 0.7182\n",
      "Epoch 12: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 1.3859 - accuracy: 0.7182 - val_loss: 1.4152 - val_accuracy: 0.7267\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.2907 - accuracy: 0.7228\n",
      "Epoch 13: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 1.2907 - accuracy: 0.7228 - val_loss: 1.5564 - val_accuracy: 0.7178\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.3093 - accuracy: 0.7256\n",
      "Epoch 14: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 1.3093 - accuracy: 0.7256 - val_loss: 1.3638 - val_accuracy: 0.7313\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.2188 - accuracy: 0.7285\n",
      "Epoch 15: val_loss did not improve from 1.04872\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 1.2188 - accuracy: 0.7285 - val_loss: 1.7379 - val_accuracy: 0.7132\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.1638 - accuracy: 0.7285\n",
      "Epoch 16: val_loss improved from 1.04872 to 1.03531, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 1.1638 - accuracy: 0.7285 - val_loss: 1.0353 - val_accuracy: 0.7286\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.1583 - accuracy: 0.7259\n",
      "Epoch 17: val_loss did not improve from 1.03531\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 1.1583 - accuracy: 0.7259 - val_loss: 1.0700 - val_accuracy: 0.7286\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.1974 - accuracy: 0.7120\n",
      "Epoch 18: val_loss did not improve from 1.03531\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 1.1974 - accuracy: 0.7120 - val_loss: 1.6602 - val_accuracy: 0.7038\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.2548 - accuracy: 0.6974\n",
      "Epoch 19: val_loss improved from 1.03531 to 0.94170, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 1.2548 - accuracy: 0.6974 - val_loss: 0.9417 - val_accuracy: 0.6107\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.3122 - accuracy: 0.6661\n",
      "Epoch 20: val_loss did not improve from 0.94170\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 1.3122 - accuracy: 0.6661 - val_loss: 1.2506 - val_accuracy: 0.6717\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0281 - accuracy: 0.6504\n",
      "Epoch 21: val_loss improved from 0.94170 to 0.76448, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 1.0281 - accuracy: 0.6504 - val_loss: 0.7645 - val_accuracy: 0.7038\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0866 - accuracy: 0.6925\n",
      "Epoch 22: val_loss improved from 0.76448 to 0.76076, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 1.0866 - accuracy: 0.6925 - val_loss: 0.7608 - val_accuracy: 0.6994\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.6661\n",
      "Epoch 23: val_loss did not improve from 0.76076\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.8728 - accuracy: 0.6661 - val_loss: 0.9619 - val_accuracy: 0.6599\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.6506\n",
      "Epoch 24: val_loss did not improve from 0.76076\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.9929 - accuracy: 0.6506 - val_loss: 0.8245 - val_accuracy: 0.7053\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0244 - accuracy: 0.6959\n",
      "Epoch 25: val_loss did not improve from 0.76076\n",
      "19/19 [==============================] - 3s 152ms/step - loss: 1.0244 - accuracy: 0.6959 - val_loss: 0.8792 - val_accuracy: 0.6966\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8992 - accuracy: 0.6904\n",
      "Epoch 26: val_loss did not improve from 0.76076\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.8992 - accuracy: 0.6904 - val_loss: 0.8833 - val_accuracy: 0.6970\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8782 - accuracy: 0.6812\n",
      "Epoch 27: val_loss did not improve from 0.76076\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.8782 - accuracy: 0.6812 - val_loss: 0.8110 - val_accuracy: 0.6506\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8461 - accuracy: 0.6693\n",
      "Epoch 28: val_loss improved from 0.76076 to 0.72448, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.8461 - accuracy: 0.6693 - val_loss: 0.7245 - val_accuracy: 0.7033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.6694\n",
      "Epoch 29: val_loss improved from 0.72448 to 0.70587, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.9316 - accuracy: 0.6694 - val_loss: 0.7059 - val_accuracy: 0.6538\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8116 - accuracy: 0.6832\n",
      "Epoch 30: val_loss did not improve from 0.70587\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.8116 - accuracy: 0.6832 - val_loss: 0.8566 - val_accuracy: 0.6439\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.6729\n",
      "Epoch 31: val_loss improved from 0.70587 to 0.70313, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.9428 - accuracy: 0.6729 - val_loss: 0.7031 - val_accuracy: 0.6846\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7770 - accuracy: 0.6618\n",
      "Epoch 32: val_loss did not improve from 0.70313\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7770 - accuracy: 0.6618 - val_loss: 0.7838 - val_accuracy: 0.6743\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.6822\n",
      "Epoch 33: val_loss improved from 0.70313 to 0.69224, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.8419 - accuracy: 0.6822 - val_loss: 0.6922 - val_accuracy: 0.7148\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8582 - accuracy: 0.6699\n",
      "Epoch 34: val_loss improved from 0.69224 to 0.67861, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.8582 - accuracy: 0.6699 - val_loss: 0.6786 - val_accuracy: 0.6463\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8572 - accuracy: 0.6754\n",
      "Epoch 35: val_loss did not improve from 0.67861\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.8572 - accuracy: 0.6754 - val_loss: 0.7713 - val_accuracy: 0.6869\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.6970\n",
      "Epoch 36: val_loss did not improve from 0.67861\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7942 - accuracy: 0.6970 - val_loss: 0.7307 - val_accuracy: 0.7207\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8207 - accuracy: 0.7119\n",
      "Epoch 37: val_loss did not improve from 0.67861\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.8207 - accuracy: 0.7119 - val_loss: 0.7518 - val_accuracy: 0.6796\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8979 - accuracy: 0.6945\n",
      "Epoch 38: val_loss improved from 0.67861 to 0.66040, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.8979 - accuracy: 0.6945 - val_loss: 0.6604 - val_accuracy: 0.6770\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.6903\n",
      "Epoch 39: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.8695 - accuracy: 0.6903 - val_loss: 0.9509 - val_accuracy: 0.6765\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8801 - accuracy: 0.6942\n",
      "Epoch 40: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.8801 - accuracy: 0.6942 - val_loss: 0.7178 - val_accuracy: 0.7062\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7657 - accuracy: 0.6965\n",
      "Epoch 41: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.7657 - accuracy: 0.6965 - val_loss: 0.7212 - val_accuracy: 0.7114\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7777 - accuracy: 0.7021\n",
      "Epoch 42: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7777 - accuracy: 0.7021 - val_loss: 0.6907 - val_accuracy: 0.6898\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8276 - accuracy: 0.7156\n",
      "Epoch 43: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.8276 - accuracy: 0.7156 - val_loss: 0.7523 - val_accuracy: 0.7289\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.7183\n",
      "Epoch 44: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.8192 - accuracy: 0.7183 - val_loss: 1.3388 - val_accuracy: 0.6542\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8404 - accuracy: 0.6947\n",
      "Epoch 45: val_loss did not improve from 0.66040\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.8404 - accuracy: 0.6947 - val_loss: 0.6696 - val_accuracy: 0.7319\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7417 - accuracy: 0.6960\n",
      "Epoch 46: val_loss improved from 0.66040 to 0.63306, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.7417 - accuracy: 0.6960 - val_loss: 0.6331 - val_accuracy: 0.7109\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7154 - accuracy: 0.7112\n",
      "Epoch 47: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7154 - accuracy: 0.7112 - val_loss: 0.7793 - val_accuracy: 0.7163\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7623 - accuracy: 0.7171\n",
      "Epoch 48: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7623 - accuracy: 0.7171 - val_loss: 0.7619 - val_accuracy: 0.7069\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.7217\n",
      "Epoch 49: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7608 - accuracy: 0.7217 - val_loss: 0.7252 - val_accuracy: 0.7215\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.7188\n",
      "Epoch 50: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.7584 - accuracy: 0.7188 - val_loss: 0.9695 - val_accuracy: 0.7124\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7537 - accuracy: 0.7243\n",
      "Epoch 51: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7537 - accuracy: 0.7243 - val_loss: 0.7067 - val_accuracy: 0.7193\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7328\n",
      "Epoch 52: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.7646 - accuracy: 0.7328 - val_loss: 0.7367 - val_accuracy: 0.7256\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.7259\n",
      "Epoch 53: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7701 - accuracy: 0.7259 - val_loss: 0.6416 - val_accuracy: 0.7291\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.7220\n",
      "Epoch 54: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7483 - accuracy: 0.7220 - val_loss: 0.7064 - val_accuracy: 0.7298\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.7320\n",
      "Epoch 55: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7702 - accuracy: 0.7320 - val_loss: 0.8629 - val_accuracy: 0.7238\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8268 - accuracy: 0.7279\n",
      "Epoch 56: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.8268 - accuracy: 0.7279 - val_loss: 0.7922 - val_accuracy: 0.7335\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8004 - accuracy: 0.7350\n",
      "Epoch 57: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.8004 - accuracy: 0.7350 - val_loss: 0.7965 - val_accuracy: 0.7194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7522 - accuracy: 0.7334\n",
      "Epoch 58: val_loss did not improve from 0.63306\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7522 - accuracy: 0.7334 - val_loss: 0.8191 - val_accuracy: 0.7490\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.7316\n",
      "Epoch 59: val_loss improved from 0.63306 to 0.62314, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.7625 - accuracy: 0.7316 - val_loss: 0.6231 - val_accuracy: 0.7359\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7789 - accuracy: 0.7264\n",
      "Epoch 60: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7789 - accuracy: 0.7264 - val_loss: 0.7184 - val_accuracy: 0.7320\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7658 - accuracy: 0.7420\n",
      "Epoch 61: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7658 - accuracy: 0.7420 - val_loss: 0.7363 - val_accuracy: 0.7436\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7454 - accuracy: 0.7425\n",
      "Epoch 62: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.7454 - accuracy: 0.7425 - val_loss: 0.6915 - val_accuracy: 0.7482\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.7469\n",
      "Epoch 63: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7294 - accuracy: 0.7469 - val_loss: 0.6995 - val_accuracy: 0.7447\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.7485\n",
      "Epoch 64: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7319 - accuracy: 0.7485 - val_loss: 0.8204 - val_accuracy: 0.7420\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7764 - accuracy: 0.7474\n",
      "Epoch 65: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7764 - accuracy: 0.7474 - val_loss: 0.7079 - val_accuracy: 0.7501\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.7497\n",
      "Epoch 66: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7310 - accuracy: 0.7497 - val_loss: 0.7577 - val_accuracy: 0.7526\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.7522\n",
      "Epoch 67: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7622 - accuracy: 0.7522 - val_loss: 0.7333 - val_accuracy: 0.7590\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7524 - accuracy: 0.7468\n",
      "Epoch 68: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7524 - accuracy: 0.7468 - val_loss: 0.7168 - val_accuracy: 0.7600\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7593 - accuracy: 0.7459\n",
      "Epoch 69: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7593 - accuracy: 0.7459 - val_loss: 0.7732 - val_accuracy: 0.7645\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7686 - accuracy: 0.7538\n",
      "Epoch 70: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7686 - accuracy: 0.7538 - val_loss: 0.7077 - val_accuracy: 0.7573\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7610 - accuracy: 0.7506\n",
      "Epoch 71: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7610 - accuracy: 0.7506 - val_loss: 0.7205 - val_accuracy: 0.7580\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.7538\n",
      "Epoch 72: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7229 - accuracy: 0.7538 - val_loss: 0.6421 - val_accuracy: 0.7512\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.7492\n",
      "Epoch 73: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.7476 - accuracy: 0.7492 - val_loss: 0.6983 - val_accuracy: 0.7611\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.7522\n",
      "Epoch 74: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7369 - accuracy: 0.7522 - val_loss: 0.8016 - val_accuracy: 0.7602\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.7537\n",
      "Epoch 75: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7481 - accuracy: 0.7537 - val_loss: 0.8090 - val_accuracy: 0.7432\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7450 - accuracy: 0.7530\n",
      "Epoch 76: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.7450 - accuracy: 0.7530 - val_loss: 0.8958 - val_accuracy: 0.7435\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.7562\n",
      "Epoch 77: val_loss did not improve from 0.62314\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7735 - accuracy: 0.7562 - val_loss: 0.8597 - val_accuracy: 0.7215\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.7451\n",
      "Epoch 78: val_loss improved from 0.62314 to 0.61973, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.8203 - accuracy: 0.7451 - val_loss: 0.6197 - val_accuracy: 0.7533\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7865 - accuracy: 0.7540\n",
      "Epoch 79: val_loss did not improve from 0.61973\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7865 - accuracy: 0.7540 - val_loss: 0.7975 - val_accuracy: 0.7582\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7773 - accuracy: 0.7506\n",
      "Epoch 80: val_loss did not improve from 0.61973\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.7773 - accuracy: 0.7506 - val_loss: 0.7688 - val_accuracy: 0.7608\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.7466\n",
      "Epoch 81: val_loss did not improve from 0.61973\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7927 - accuracy: 0.7466 - val_loss: 0.6400 - val_accuracy: 0.7588\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7761 - accuracy: 0.7553\n",
      "Epoch 82: val_loss did not improve from 0.61973\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7761 - accuracy: 0.7553 - val_loss: 0.7264 - val_accuracy: 0.7600\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8059 - accuracy: 0.7515\n",
      "Epoch 83: val_loss did not improve from 0.61973\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.8059 - accuracy: 0.7515 - val_loss: 0.6293 - val_accuracy: 0.7635\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.7604\n",
      "Epoch 84: val_loss improved from 0.61973 to 0.61568, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7896 - accuracy: 0.7604 - val_loss: 0.6157 - val_accuracy: 0.7578\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7628 - accuracy: 0.7592\n",
      "Epoch 85: val_loss did not improve from 0.61568\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7628 - accuracy: 0.7592 - val_loss: 0.6263 - val_accuracy: 0.7641\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.7631\n",
      "Epoch 86: val_loss did not improve from 0.61568\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7405 - accuracy: 0.7631 - val_loss: 0.6686 - val_accuracy: 0.7596\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.7624\n",
      "Epoch 87: val_loss improved from 0.61568 to 0.60901, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.7633 - accuracy: 0.7624 - val_loss: 0.6090 - val_accuracy: 0.7430\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7380 - accuracy: 0.7510\n",
      "Epoch 88: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7380 - accuracy: 0.7510 - val_loss: 0.8220 - val_accuracy: 0.7391\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8572 - accuracy: 0.7361\n",
      "Epoch 89: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 155ms/step - loss: 0.8572 - accuracy: 0.7361 - val_loss: 0.7110 - val_accuracy: 0.6999\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.7322\n",
      "Epoch 90: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.6906 - accuracy: 0.7322 - val_loss: 0.7418 - val_accuracy: 0.7653\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7461 - accuracy: 0.7675\n",
      "Epoch 91: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7461 - accuracy: 0.7675 - val_loss: 0.8251 - val_accuracy: 0.7444\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7741 - accuracy: 0.7555\n",
      "Epoch 92: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7741 - accuracy: 0.7555 - val_loss: 0.6987 - val_accuracy: 0.7633\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.7640\n",
      "Epoch 93: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.7205 - accuracy: 0.7640 - val_loss: 0.6967 - val_accuracy: 0.7695\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7400 - accuracy: 0.7669\n",
      "Epoch 94: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7400 - accuracy: 0.7669 - val_loss: 0.6881 - val_accuracy: 0.7672\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.7648\n",
      "Epoch 95: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.7210 - accuracy: 0.7648 - val_loss: 0.7872 - val_accuracy: 0.7659\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7366 - accuracy: 0.7639\n",
      "Epoch 96: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.7366 - accuracy: 0.7639 - val_loss: 0.7624 - val_accuracy: 0.7591\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.7679\n",
      "Epoch 97: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.7216 - accuracy: 0.7679 - val_loss: 0.7138 - val_accuracy: 0.7611\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7810 - accuracy: 0.7697\n",
      "Epoch 98: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7810 - accuracy: 0.7697 - val_loss: 0.6459 - val_accuracy: 0.7624\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.7682\n",
      "Epoch 99: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7169 - accuracy: 0.7682 - val_loss: 0.7618 - val_accuracy: 0.7717\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.7694\n",
      "Epoch 100: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7266 - accuracy: 0.7694 - val_loss: 0.6567 - val_accuracy: 0.7809\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.7748\n",
      "Epoch 101: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.6944 - accuracy: 0.7748 - val_loss: 0.8107 - val_accuracy: 0.7793\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7761\n",
      "Epoch 102: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.7182 - accuracy: 0.7761 - val_loss: 0.6921 - val_accuracy: 0.7721\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7189 - accuracy: 0.7709\n",
      "Epoch 103: val_loss did not improve from 0.60901\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7189 - accuracy: 0.7709 - val_loss: 1.3068 - val_accuracy: 0.7125\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7441 - accuracy: 0.7690\n",
      "Epoch 104: val_loss improved from 0.60901 to 0.59503, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7441 - accuracy: 0.7690 - val_loss: 0.5950 - val_accuracy: 0.7746\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.7482\n",
      "Epoch 105: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.7570 - accuracy: 0.7482 - val_loss: 0.6012 - val_accuracy: 0.7604\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.7517\n",
      "Epoch 106: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7331 - accuracy: 0.7517 - val_loss: 0.7153 - val_accuracy: 0.7624\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.7715\n",
      "Epoch 107: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 154ms/step - loss: 0.7310 - accuracy: 0.7715 - val_loss: 0.6831 - val_accuracy: 0.7756\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7123 - accuracy: 0.7707\n",
      "Epoch 108: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7123 - accuracy: 0.7707 - val_loss: 0.6541 - val_accuracy: 0.7678\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.7612\n",
      "Epoch 109: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7391 - accuracy: 0.7612 - val_loss: 0.6050 - val_accuracy: 0.7464\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7954 - accuracy: 0.7402\n",
      "Epoch 110: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.7954 - accuracy: 0.7402 - val_loss: 0.6003 - val_accuracy: 0.7545\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7148 - accuracy: 0.7504\n",
      "Epoch 111: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7148 - accuracy: 0.7504 - val_loss: 0.7829 - val_accuracy: 0.7712\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.7729\n",
      "Epoch 112: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7601 - accuracy: 0.7729 - val_loss: 0.7430 - val_accuracy: 0.7847\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.7749\n",
      "Epoch 113: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.7085 - accuracy: 0.7749 - val_loss: 0.6290 - val_accuracy: 0.7757\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.7712\n",
      "Epoch 114: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.7013 - accuracy: 0.7712 - val_loss: 0.7656 - val_accuracy: 0.7718\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.7747\n",
      "Epoch 115: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.6953 - accuracy: 0.7747 - val_loss: 0.6672 - val_accuracy: 0.7827\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.7761\n",
      "Epoch 116: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7233 - accuracy: 0.7761 - val_loss: 0.7838 - val_accuracy: 0.7488\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7361 - accuracy: 0.7769\n",
      "Epoch 117: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.7361 - accuracy: 0.7769 - val_loss: 0.6320 - val_accuracy: 0.7816\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.7720\n",
      "Epoch 118: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 148ms/step - loss: 0.7397 - accuracy: 0.7720 - val_loss: 0.6192 - val_accuracy: 0.7748\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.7697\n",
      "Epoch 119: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.7035 - accuracy: 0.7697 - val_loss: 0.6836 - val_accuracy: 0.7618\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.7762\n",
      "Epoch 120: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.6748 - accuracy: 0.7762 - val_loss: 0.6909 - val_accuracy: 0.7845\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.7798\n",
      "Epoch 121: val_loss did not improve from 0.59503\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.6945 - accuracy: 0.7798 - val_loss: 0.6094 - val_accuracy: 0.7415\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.7517\n",
      "Epoch 122: val_loss improved from 0.59503 to 0.58810, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.7895 - accuracy: 0.7517 - val_loss: 0.5881 - val_accuracy: 0.7684\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.7637\n",
      "Epoch 123: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.6745 - accuracy: 0.7637 - val_loss: 0.7354 - val_accuracy: 0.7302\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7765\n",
      "Epoch 124: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.7395 - accuracy: 0.7765 - val_loss: 0.6113 - val_accuracy: 0.7629\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6983 - accuracy: 0.7748\n",
      "Epoch 125: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 143ms/step - loss: 0.6983 - accuracy: 0.7748 - val_loss: 0.7912 - val_accuracy: 0.7754\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.7687\n",
      "Epoch 126: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.6995 - accuracy: 0.7687 - val_loss: 0.6630 - val_accuracy: 0.7884\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.7778\n",
      "Epoch 127: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.7225 - accuracy: 0.7778 - val_loss: 0.7040 - val_accuracy: 0.7925\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.7846\n",
      "Epoch 128: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.6989 - accuracy: 0.7846 - val_loss: 0.6105 - val_accuracy: 0.7783\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.7706\n",
      "Epoch 129: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7150 - accuracy: 0.7706 - val_loss: 0.6613 - val_accuracy: 0.7811\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.7867\n",
      "Epoch 130: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7195 - accuracy: 0.7867 - val_loss: 0.6123 - val_accuracy: 0.7941\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.7767\n",
      "Epoch 131: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.7200 - accuracy: 0.7767 - val_loss: 0.6055 - val_accuracy: 0.7856\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.7796\n",
      "Epoch 132: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.7125 - accuracy: 0.7796 - val_loss: 0.9363 - val_accuracy: 0.7631\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.7834\n",
      "Epoch 133: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7071 - accuracy: 0.7834 - val_loss: 0.7536 - val_accuracy: 0.7617\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.7851\n",
      "Epoch 134: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.7335 - accuracy: 0.7851 - val_loss: 0.9002 - val_accuracy: 0.8016\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.7836\n",
      "Epoch 135: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7308 - accuracy: 0.7836 - val_loss: 1.2941 - val_accuracy: 0.7263\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.7817\n",
      "Epoch 136: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.7881 - accuracy: 0.7817 - val_loss: 0.6369 - val_accuracy: 0.8012\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.7884\n",
      "Epoch 137: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7176 - accuracy: 0.7884 - val_loss: 0.6584 - val_accuracy: 0.7810\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.7855\n",
      "Epoch 138: val_loss did not improve from 0.58810\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.6968 - accuracy: 0.7855 - val_loss: 0.7370 - val_accuracy: 0.7971\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.7878\n",
      "Epoch 139: val_loss improved from 0.58810 to 0.58807, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7070 - accuracy: 0.7878 - val_loss: 0.5881 - val_accuracy: 0.7925\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.7894\n",
      "Epoch 140: val_loss did not improve from 0.58807\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.7036 - accuracy: 0.7894 - val_loss: 0.6680 - val_accuracy: 0.7961\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.7954\n",
      "Epoch 141: val_loss did not improve from 0.58807\n",
      "19/19 [==============================] - 3s 142ms/step - loss: 0.6972 - accuracy: 0.7954 - val_loss: 0.7128 - val_accuracy: 0.7851\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.7893\n",
      "Epoch 142: val_loss improved from 0.58807 to 0.55484, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.6970 - accuracy: 0.7893 - val_loss: 0.5548 - val_accuracy: 0.7983\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.7879\n",
      "Epoch 143: val_loss improved from 0.55484 to 0.54180, saving model to qgru_1int_test3\\model_qgru_2frac.h5\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.7040 - accuracy: 0.7879 - val_loss: 0.5418 - val_accuracy: 0.7908\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.7873\n",
      "Epoch 144: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.7204 - accuracy: 0.7873 - val_loss: 0.7672 - val_accuracy: 0.7746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7926\n",
      "Epoch 145: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.6553 - accuracy: 0.7926 - val_loss: 0.6192 - val_accuracy: 0.7867\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6711 - accuracy: 0.7879\n",
      "Epoch 146: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.6711 - accuracy: 0.7879 - val_loss: 0.7671 - val_accuracy: 0.8053\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7114 - accuracy: 0.7921\n",
      "Epoch 147: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.7114 - accuracy: 0.7921 - val_loss: 0.6813 - val_accuracy: 0.7932\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.7944\n",
      "Epoch 148: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 145ms/step - loss: 0.6880 - accuracy: 0.7944 - val_loss: 0.6840 - val_accuracy: 0.8005\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.7962\n",
      "Epoch 149: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.6844 - accuracy: 0.7962 - val_loss: 0.6052 - val_accuracy: 0.7979\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.7924\n",
      "Epoch 150: val_loss did not improve from 0.54180\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.6788 - accuracy: 0.7924 - val_loss: 0.6386 - val_accuracy: 0.7953\n",
      "624/624 [==============================] - 37s 58ms/step\n",
      "0.8626968511256639\n"
     ]
    }
   ],
   "source": [
    "GRU_2int = []\n",
    "GRU_4int = []\n",
    "for j in [1]:\n",
    "    for i in [2]:\n",
    "        int_bits = j\n",
    "        total_bits = i + int_bits + 1\n",
    "        config = {\n",
    "            \"QGRU\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"bias_quantizer\" : f\"quantized_bits({total_bits}, {int_bits},1)\",\n",
    "                 \"recurrent_quantizer\": f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"state_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"QDense\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                \"bias_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"relu_0\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "            \"relu_1\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "        }\n",
    "    \n",
    "        qmodel = model_quantize(model, config, total_bits, transfer_weights=True)\n",
    "        qmodel.summary()\n",
    "        \n",
    "        es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=20)\n",
    "        adam = Adam(lr = 0.0002)\n",
    "    \n",
    "        qmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = qmodel.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 2**14,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint(f'qgru_{j}int_test3/model_qgru_{i}frac.h5', verbose=1, save_best_only=True), es],\n",
    "                    use_multiprocessing=True, workers=4)\n",
    "        \n",
    "        labels = ['j_t']\n",
    "        y_keras = qmodel.predict(x_test)\n",
    "        auc_score = roc_auc_score(y_test, y_keras)\n",
    "        print(auc_score)\n",
    "        if j == 2:\n",
    "            GRU_2int.append(auc_score)\n",
    "        else:\n",
    "            GRU_4int.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "818d781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_2int = [0.8889239320342668, 0.9130811006719319, 0.9166560291073371, 0.9166675510362661, 0.9184637408665223, 0.9156683138854429, 0.911016851381327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e169f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_4int = [0.8968693044839106, 0.9138026005450852, 0.9159394334655987, 0.9175075966343627, 0.9139816954386266, 0.9055667277565066, 0.8972966007204316]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d2dba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.95)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "float_gru = [0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996]\n",
    "plt.plot([2,4,6,8,10,12,14], float_gru, \"-\", label = \"floating point\")\n",
    "plt.plot([2,4,6,8,10,12,14], GRU_2int, \"-o\", label = '2 int')\n",
    "plt.plot([2,4,6,8,10,12,14], GRU_4int, \"-o\", label = '4 int')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"fractional bits\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"QGRU QAT\")\n",
    "plt.grid()\n",
    "plt.ylim([0.5, 0.95]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee845b",
   "metadata": {},
   "source": [
    "## QGRU weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "427bee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer1': {'weights': [array([[ 0.34375   ,  0.15625   , -0.15625   , -0.28125   ,  0.1875    ,\n",
       "            0.5       , -0.25      ,  0.        ,  0.375     ,  0.        ,\n",
       "           -0.0625    , -0.1875    ,  0.125     ,  0.046875  , -0.21875   ,\n",
       "            0.125     ,  0.625     ,  0.09375   , -0.375     , -0.03125   ,\n",
       "            0.125     ,  0.        , -0.0625    , -0.15625   ,  0.        ,\n",
       "           -0.125     ,  0.21875   , -0.21875   , -0.375     , -0.21875   ,\n",
       "            0.        , -0.25      ,  0.125     ,  0.375     , -0.375     ,\n",
       "            0.05078125, -0.125     ,  0.125     ,  0.        , -0.125     ,\n",
       "            1.125     , -0.34375   ,  0.125     ,  0.125     , -0.25      ,\n",
       "            0.5       ,  0.5       , -0.125     , -0.125     , -0.25      ,\n",
       "           -0.28125   ,  0.4375    ,  0.625     , -0.5       , -0.5       ,\n",
       "           -1.375     , -0.25      , -0.8125    , -0.3125    , -0.0625    ],\n",
       "          [-0.46875   , -0.0625    , -0.40625   , -0.0625    , -0.4375    ,\n",
       "           -0.625     , -0.4375    , -0.4375    , -0.03125   ,  0.        ,\n",
       "           -0.4375    , -0.6875    , -0.0625    , -0.21875   , -0.4375    ,\n",
       "           -0.40625   , -0.0625    , -0.28125   , -0.1875    ,  0.        ,\n",
       "            0.046875  ,  0.234375  , -0.09375   , -0.1875    ,  0.46875   ,\n",
       "            0.3125    , -0.375     , -0.09375   ,  0.3125    , -0.25      ,\n",
       "            0.        ,  0.0625    , -0.625     ,  0.03125   , -0.5625    ,\n",
       "           -0.00390625,  0.0625    ,  0.        , -0.21875   ,  0.1875    ,\n",
       "            0.        ,  0.1875    ,  0.1875    , -0.375     ,  0.125     ,\n",
       "            0.5       , -0.25      ,  0.375     ,  0.5       ,  0.5       ,\n",
       "           -0.46875   , -0.5       , -0.125     , -0.25      , -0.25      ,\n",
       "           -0.5       , -0.625     ,  0.1875    , -0.5625    ,  0.125     ],\n",
       "          [-0.34375   , -0.4375    , -0.15625   , -0.375     ,  0.        ,\n",
       "            0.375     , -0.375     , -0.15625   , -0.28125   , -0.234375  ,\n",
       "           -0.0625    , -0.375     , -0.46875   , -0.234375  , -0.4375    ,\n",
       "           -0.125     ,  0.375     , -0.375     , -0.46875   ,  0.03125   ,\n",
       "           -0.046875  , -0.234375  ,  0.0625    ,  0.40625   ,  0.03125   ,\n",
       "            0.6875    ,  0.0625    ,  0.        , -0.125     ,  0.375     ,\n",
       "            0.1171875 ,  0.5625    ,  0.        , -0.03125   , -0.625     ,\n",
       "           -0.00390625, -0.4375    , -0.5       , -0.125     , -0.40625   ,\n",
       "            0.375     ,  0.46875   , -0.4375    , -0.46875   ,  0.375     ,\n",
       "           -0.5       ,  0.5       ,  0.625     ,  0.375     ,  0.125     ,\n",
       "           -0.46875   ,  0.4375    , -0.5       ,  0.25      , -0.25      ,\n",
       "           -0.375     ,  0.375     ,  0.125     ,  0.        ,  0.5       ],\n",
       "          [ 0.34375   ,  0.0625    , -0.15625   , -0.3125    ,  0.28125   ,\n",
       "            0.75      , -0.28125   , -0.03125   ,  0.375     ,  0.        ,\n",
       "           -0.3125    , -0.1875    ,  0.0625    , -0.015625  , -0.1875    ,\n",
       "            0.46875   ,  0.875     ,  0.09375   , -0.34375   , -0.125     ,\n",
       "            0.015625  ,  0.046875  , -0.09375   , -0.21875   , -0.375     ,\n",
       "           -0.125     ,  0.4375    , -0.0625    , -0.6875    , -0.21875   ,\n",
       "            0.        , -0.375     ,  0.3125    ,  0.25      , -0.1875    ,\n",
       "           -0.00390625, -0.125     ,  0.375     ,  0.03125   , -0.15625   ,\n",
       "            0.5       ,  0.34375   , -0.6875    , -0.40625   ,  0.625     ,\n",
       "            0.5       , -0.375     ,  0.        , -0.875     ,  0.125     ,\n",
       "           -0.46875   , -0.3125    ,  0.        , -0.25      ,  0.625     ,\n",
       "           -1.125     , -0.5       , -0.25      , -0.3125    , -0.3125    ],\n",
       "          [-0.03125   , -0.125     ,  0.        ,  0.09375   ,  0.        ,\n",
       "            0.        , -0.3125    ,  0.        ,  0.        ,  0.        ,\n",
       "            0.        ,  0.        , -0.03125   , -0.109375  ,  0.        ,\n",
       "           -0.21875   , -0.0625    ,  0.        ,  0.        ,  0.        ,\n",
       "            0.140625  ,  0.        , -0.46875   , -0.46875   , -0.46875   ,\n",
       "           -0.9375    ,  0.375     ,  0.46875   , -0.5625    , -0.15625   ,\n",
       "            0.        , -0.9375    ,  0.9375    ,  0.25      , -0.75      ,\n",
       "            0.015625  , -0.8125    ,  1.625     ,  0.375     , -0.40625   ,\n",
       "            1.5       ,  0.46875   ,  0.6875    ,  0.46875   ,  1.625     ,\n",
       "            1.75      , -1.875     , -1.625     , -1.875     , -1.875     ,\n",
       "            0.46875   , -0.9375    ,  1.75      , -1.375     ,  1.5       ,\n",
       "           -1.75      , -1.375     , -0.9375    ,  0.9375    , -0.75      ],\n",
       "          [-0.09375   ,  0.3125    , -0.09375   ,  0.0625    , -0.46875   ,\n",
       "           -0.1875    , -0.46875   ,  0.0625    , -0.03125   , -0.078125  ,\n",
       "           -0.46875   , -0.125     , -0.125     ,  0.234375  , -0.375     ,\n",
       "            0.28125   , -0.125     , -0.0625    , -0.34375   , -0.34375   ,\n",
       "            0.171875  ,  0.21875   ,  0.3125    ,  0.46875   ,  0.34375   ,\n",
       "           -0.1875    , -0.375     , -0.46875   , -0.25      , -0.46875   ,\n",
       "            0.109375  ,  0.375     ,  0.6875    , -0.46875   ,  0.6875    ,\n",
       "            0.01171875,  0.125     , -0.125     , -0.0625    , -0.4375    ,\n",
       "            0.        ,  0.125     , -0.0625    , -0.4375    , -0.25      ,\n",
       "            0.375     , -0.125     , -0.875     , -0.375     , -0.5       ,\n",
       "            0.1875    ,  0.375     ,  0.625     , -0.125     , -0.25      ,\n",
       "           -0.5       , -0.125     ,  0.5625    , -0.3125    ,  0.75      ]],\n",
       "         dtype=float32),\n",
       "   array([[-0.1875  ,  0.125   , -0.25    , ..., -0.0625  , -0.078125,\n",
       "           -0.09375 ],\n",
       "          [-0.5     , -0.15625 , -0.34375 , ..., -0.1875  ,  0.15625 ,\n",
       "            0.21875 ],\n",
       "          [ 0.375   ,  0.      ,  0.46875 , ...,  0.234375, -0.234375,\n",
       "            0.0625  ],\n",
       "          ...,\n",
       "          [-0.25    ,  0.1875  ,  0.0625  , ..., -0.046875,  0.09375 ,\n",
       "            0.      ],\n",
       "          [ 0.25    ,  0.0625  ,  0.28125 , ...,  0.03125 ,  0.078125,\n",
       "            0.      ],\n",
       "          [-0.6875  , -0.03125 , -0.4375  , ...,  0.0625  ,  0.140625,\n",
       "           -0.09375 ]], dtype=float32),\n",
       "   array([[-0.25,  0.  , -0.25, -0.25, -0.5 , -0.25, -0.25, -0.5 , -0.25,\n",
       "           -0.5 , -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25,\n",
       "           -0.25, -0.25,  0.25,  0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.  ,  0.  ,  0.25,  0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "          [-0.25,  0.  , -0.25, -0.25, -0.5 , -0.25, -0.25, -0.5 , -0.25,\n",
       "           -0.5 , -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25,\n",
       "           -0.25, -0.25,  0.25,  0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.  ,  0.  ,  0.25,  0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "            0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ]], dtype=float32)]},\n",
       " 'layer3': {'weights': [array([[-0.015625, -0.09375 , -0.234375, ...,  0.09375 ,  0.0625  ,\n",
       "           -0.09375 ],\n",
       "          [ 0.09375 ,  0.1875  , -0.21875 , ...,  0.125   , -0.03125 ,\n",
       "            0.125   ],\n",
       "          [-0.09375 ,  0.34375 , -0.125   , ..., -0.015625, -0.234375,\n",
       "            0.21875 ],\n",
       "          ...,\n",
       "          [ 0.03125 , -0.4375  ,  0.234375, ..., -0.1875  , -0.21875 ,\n",
       "           -0.21875 ],\n",
       "          [ 0.15625 ,  0.0625  , -0.046875, ..., -0.0625  , -0.140625,\n",
       "            0.03125 ],\n",
       "          [ 0.0625  , -0.40625 ,  0.046875, ..., -0.140625, -0.171875,\n",
       "            0.3125  ]], dtype=float32),\n",
       "   array([ 0.  ,  0.  ,  0.  ,  0.25, -0.25,  0.  , -0.25,  0.  ,  0.  ,\n",
       "           0.  , -0.25,  0.  , -0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.  ,  0.  ,  0.  , -0.25,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.  , -0.25, -0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.  , -0.25, -0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  , -0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.  , -0.25,  0.  ,  0.  ,  0.  , -0.25,  0.  ,  0.  ,\n",
       "           0.  ], dtype=float32)]},\n",
       " 'output_sigmoid': {'weights': [array([[ 0.0625  ],\n",
       "          [-0.203125],\n",
       "          [-0.046875],\n",
       "          [-0.171875],\n",
       "          [ 0.125   ],\n",
       "          [-0.203125],\n",
       "          [ 0.234375],\n",
       "          [ 0.140625],\n",
       "          [-0.0625  ],\n",
       "          [-0.125   ],\n",
       "          [ 0.234375],\n",
       "          [-0.234375],\n",
       "          [ 0.015625],\n",
       "          [ 0.09375 ],\n",
       "          [-0.015625],\n",
       "          [ 0.1875  ],\n",
       "          [-0.203125],\n",
       "          [-0.078125],\n",
       "          [-0.234375],\n",
       "          [-0.140625],\n",
       "          [ 0.203125],\n",
       "          [-0.1875  ],\n",
       "          [ 0.1875  ],\n",
       "          [ 0.0625  ],\n",
       "          [-0.234375],\n",
       "          [ 0.171875],\n",
       "          [-0.140625],\n",
       "          [ 0.203125],\n",
       "          [-0.109375],\n",
       "          [ 0.234375],\n",
       "          [ 0.0625  ],\n",
       "          [ 0.15625 ],\n",
       "          [ 0.015625],\n",
       "          [-0.140625],\n",
       "          [ 0.      ],\n",
       "          [-0.234375],\n",
       "          [ 0.      ],\n",
       "          [ 0.078125],\n",
       "          [ 0.234375],\n",
       "          [ 0.21875 ],\n",
       "          [-0.140625],\n",
       "          [ 0.046875],\n",
       "          [-0.125   ],\n",
       "          [-0.140625],\n",
       "          [-0.234375],\n",
       "          [-0.203125],\n",
       "          [ 0.046875],\n",
       "          [-0.125   ],\n",
       "          [ 0.125   ],\n",
       "          [ 0.21875 ],\n",
       "          [-0.09375 ],\n",
       "          [-0.046875],\n",
       "          [ 0.21875 ],\n",
       "          [-0.234375],\n",
       "          [-0.109375],\n",
       "          [ 0.046875],\n",
       "          [ 0.046875],\n",
       "          [ 0.0625  ],\n",
       "          [-0.234375],\n",
       "          [ 0.      ],\n",
       "          [ 0.203125],\n",
       "          [-0.171875],\n",
       "          [ 0.234375],\n",
       "          [-0.046875]], dtype=float32),\n",
       "   array([0.], dtype=float32)]}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgru = load_model('qgru_2int_test3/model_qgru_2frac.h5', custom_objects={'QGRU': QGRU, 'QDense': QDense, 'quantized_bits': quantized_bits, 'QActivation': QActivation})\n",
    "model_save_quantized_weights(qgru, f\"gru2int2fra_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd86c14",
   "metadata": {},
   "source": [
    "## QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50a9a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (GRU)                (None, 20)                1680      \n",
      "                                                                 \n",
      " layer3 (QDense)             (None, 64)                1344      \n",
      "                                                                 \n",
      " relu_0 (QActivation)        (None, 64)                0         \n",
      "                                                                 \n",
      " output_sigmoid (QDense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,089\n",
      "Trainable params: 3,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyihu\\anaconda3\\envs\\hls4ml-tutorial\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7056 - accuracy: 0.5032\n",
      "Epoch 1: val_loss improved from inf to 0.69876, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 4s 65ms/step - loss: 0.7054 - accuracy: 0.5033 - val_loss: 0.6988 - val_accuracy: 0.5025\n",
      "Epoch 2/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6975 - accuracy: 0.5210\n",
      "Epoch 2: val_loss improved from 0.69876 to 0.69490, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6973 - accuracy: 0.5220 - val_loss: 0.6949 - val_accuracy: 0.5818\n",
      "Epoch 3/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6935 - accuracy: 0.5980\n",
      "Epoch 3: val_loss improved from 0.69490 to 0.69143, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6934 - accuracy: 0.5971 - val_loss: 0.6914 - val_accuracy: 0.6144\n",
      "Epoch 4/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.6898 - accuracy: 0.6676\n",
      "Epoch 4: val_loss improved from 0.69143 to 0.68670, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6894 - accuracy: 0.6696 - val_loss: 0.6867 - val_accuracy: 0.6854\n",
      "Epoch 5/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6839 - accuracy: 0.6874\n",
      "Epoch 5: val_loss improved from 0.68670 to 0.67900, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6836 - accuracy: 0.6877 - val_loss: 0.6790 - val_accuracy: 0.7062\n",
      "Epoch 6/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6734 - accuracy: 0.7110\n",
      "Epoch 6: val_loss improved from 0.67900 to 0.66277, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6728 - accuracy: 0.7109 - val_loss: 0.6628 - val_accuracy: 0.7171\n",
      "Epoch 7/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.6486 - accuracy: 0.7350\n",
      "Epoch 7: val_loss improved from 0.66277 to 0.60953, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6448 - accuracy: 0.7383 - val_loss: 0.6095 - val_accuracy: 0.7482\n",
      "Epoch 8/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5496 - accuracy: 0.7691\n",
      "Epoch 8: val_loss improved from 0.60953 to 0.60487, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5486 - accuracy: 0.7685 - val_loss: 0.6049 - val_accuracy: 0.7311\n",
      "Epoch 9/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.5296 - accuracy: 0.7632\n",
      "Epoch 9: val_loss improved from 0.60487 to 0.48197, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.5232 - accuracy: 0.7667 - val_loss: 0.4820 - val_accuracy: 0.7870\n",
      "Epoch 10/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5208 - accuracy: 0.7682\n",
      "Epoch 10: val_loss improved from 0.48197 to 0.47663, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5191 - accuracy: 0.7708 - val_loss: 0.4766 - val_accuracy: 0.8062\n",
      "Epoch 11/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4654 - accuracy: 0.7976\n",
      "Epoch 11: val_loss improved from 0.47663 to 0.45203, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4642 - accuracy: 0.7989 - val_loss: 0.4520 - val_accuracy: 0.8097\n",
      "Epoch 12/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4547 - accuracy: 0.8102\n",
      "Epoch 12: val_loss improved from 0.45203 to 0.44672, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4545 - accuracy: 0.8102 - val_loss: 0.4467 - val_accuracy: 0.8115\n",
      "Epoch 13/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4468 - accuracy: 0.8116\n",
      "Epoch 13: val_loss improved from 0.44672 to 0.44449, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4463 - accuracy: 0.8117 - val_loss: 0.4445 - val_accuracy: 0.8115\n",
      "Epoch 14/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4440 - accuracy: 0.8130\n",
      "Epoch 14: val_loss did not improve from 0.44449\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4443 - accuracy: 0.8134 - val_loss: 0.4499 - val_accuracy: 0.8102\n",
      "Epoch 15/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4425 - accuracy: 0.8138\n",
      "Epoch 15: val_loss improved from 0.44449 to 0.43493, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4418 - accuracy: 0.8140 - val_loss: 0.4349 - val_accuracy: 0.8169\n",
      "Epoch 16/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4367 - accuracy: 0.8179\n",
      "Epoch 16: val_loss improved from 0.43493 to 0.43482, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4368 - accuracy: 0.8179 - val_loss: 0.4348 - val_accuracy: 0.8185\n",
      "Epoch 17/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4692 - accuracy: 0.7976\n",
      "Epoch 17: val_loss did not improve from 0.43482\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4715 - accuracy: 0.7946 - val_loss: 0.4907 - val_accuracy: 0.7607\n",
      "Epoch 18/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4712 - accuracy: 0.7978\n",
      "Epoch 18: val_loss did not improve from 0.43482\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4692 - accuracy: 0.7997 - val_loss: 0.4493 - val_accuracy: 0.8189\n",
      "Epoch 19/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4351 - accuracy: 0.8177\n",
      "Epoch 19: val_loss improved from 0.43482 to 0.42823, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4348 - accuracy: 0.8180 - val_loss: 0.4282 - val_accuracy: 0.8209\n",
      "Epoch 20/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4296 - accuracy: 0.8213\n",
      "Epoch 20: val_loss did not improve from 0.42823\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4290 - accuracy: 0.8216 - val_loss: 0.4296 - val_accuracy: 0.8203\n",
      "Epoch 21/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4269 - accuracy: 0.8229\n",
      "Epoch 21: val_loss improved from 0.42823 to 0.42441, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4270 - accuracy: 0.8226 - val_loss: 0.4244 - val_accuracy: 0.8233\n",
      "Epoch 22/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4260 - accuracy: 0.8238\n",
      "Epoch 22: val_loss improved from 0.42441 to 0.42032, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4261 - accuracy: 0.8234 - val_loss: 0.4203 - val_accuracy: 0.8241\n",
      "Epoch 23/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4221 - accuracy: 0.8251\n",
      "Epoch 23: val_loss did not improve from 0.42032\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4218 - accuracy: 0.8253 - val_loss: 0.4210 - val_accuracy: 0.8254\n",
      "Epoch 24/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4204 - accuracy: 0.8264\n",
      "Epoch 24: val_loss improved from 0.42032 to 0.41936, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4201 - accuracy: 0.8263 - val_loss: 0.4194 - val_accuracy: 0.8261\n",
      "Epoch 25/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4219 - accuracy: 0.8257\n",
      "Epoch 25: val_loss did not improve from 0.41936\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4283 - accuracy: 0.8220 - val_loss: 0.4388 - val_accuracy: 0.8210\n",
      "Epoch 26/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4399 - accuracy: 0.8144\n",
      "Epoch 26: val_loss did not improve from 0.41936\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4381 - accuracy: 0.8152 - val_loss: 0.4389 - val_accuracy: 0.8233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4294 - accuracy: 0.8213\n",
      "Epoch 27: val_loss did not improve from 0.41936\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4284 - accuracy: 0.8218 - val_loss: 0.4426 - val_accuracy: 0.8190\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8229\n",
      "Epoch 28: val_loss improved from 0.41936 to 0.41082, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4229 - accuracy: 0.8229 - val_loss: 0.4108 - val_accuracy: 0.8293\n",
      "Epoch 29/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4146 - accuracy: 0.8296\n",
      "Epoch 29: val_loss improved from 0.41082 to 0.41027, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4149 - accuracy: 0.8295 - val_loss: 0.4103 - val_accuracy: 0.8298\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.8299\n",
      "Epoch 30: val_loss improved from 0.41027 to 0.40708, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4129 - accuracy: 0.8299 - val_loss: 0.4071 - val_accuracy: 0.8310\n",
      "Epoch 31/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4190 - accuracy: 0.8254\n",
      "Epoch 31: val_loss did not improve from 0.40708\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4187 - accuracy: 0.8254 - val_loss: 0.4361 - val_accuracy: 0.8229\n",
      "Epoch 32/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4229 - accuracy: 0.8242\n",
      "Epoch 32: val_loss did not improve from 0.40708\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4216 - accuracy: 0.8247 - val_loss: 0.4085 - val_accuracy: 0.8308\n",
      "Epoch 33/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4107 - accuracy: 0.8306\n",
      "Epoch 33: val_loss improved from 0.40708 to 0.40506, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4102 - accuracy: 0.8308 - val_loss: 0.4051 - val_accuracy: 0.8319\n",
      "Epoch 34/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4068 - accuracy: 0.8327\n",
      "Epoch 34: val_loss improved from 0.40506 to 0.40317, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4071 - accuracy: 0.8326 - val_loss: 0.4032 - val_accuracy: 0.8330\n",
      "Epoch 35/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4053 - accuracy: 0.8332\n",
      "Epoch 35: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4053 - accuracy: 0.8330 - val_loss: 0.4050 - val_accuracy: 0.8328\n",
      "Epoch 36/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.7355 - accuracy: 0.5316\n",
      "Epoch 36: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.7358 - accuracy: 0.5287 - val_loss: 0.7227 - val_accuracy: 0.5001\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.5286\n",
      "Epoch 37: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6913 - accuracy: 0.5286 - val_loss: 0.6679 - val_accuracy: 0.6859\n",
      "Epoch 38/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6561 - accuracy: 0.6982\n",
      "Epoch 38: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.6547 - accuracy: 0.7025 - val_loss: 0.6346 - val_accuracy: 0.7654\n",
      "Epoch 39/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6161 - accuracy: 0.7705\n",
      "Epoch 39: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6141 - accuracy: 0.7714 - val_loss: 0.5847 - val_accuracy: 0.7883\n",
      "Epoch 40/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.5578 - accuracy: 0.7953\n",
      "Epoch 40: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5531 - accuracy: 0.7958 - val_loss: 0.5099 - val_accuracy: 0.8031\n",
      "Epoch 41/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5016 - accuracy: 0.7963\n",
      "Epoch 41: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5028 - accuracy: 0.7977 - val_loss: 0.4857 - val_accuracy: 0.7942\n",
      "Epoch 42/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4854 - accuracy: 0.8027\n",
      "Epoch 42: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4856 - accuracy: 0.8020 - val_loss: 0.4950 - val_accuracy: 0.7715\n",
      "Epoch 43/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4670 - accuracy: 0.8123\n",
      "Epoch 43: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4671 - accuracy: 0.8113 - val_loss: 0.4548 - val_accuracy: 0.8153\n",
      "Epoch 44/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4718 - accuracy: 0.8099\n",
      "Epoch 44: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4718 - accuracy: 0.8088 - val_loss: 0.4576 - val_accuracy: 0.8290\n",
      "Epoch 45/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4569 - accuracy: 0.8199\n",
      "Epoch 45: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4569 - accuracy: 0.8193 - val_loss: 0.4405 - val_accuracy: 0.8279\n",
      "Epoch 46/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4432 - accuracy: 0.8261\n",
      "Epoch 46: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4423 - accuracy: 0.8270 - val_loss: 0.4406 - val_accuracy: 0.8317\n",
      "Epoch 47/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4362 - accuracy: 0.8287\n",
      "Epoch 47: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4374 - accuracy: 0.8283 - val_loss: 0.5316 - val_accuracy: 0.7937\n",
      "Epoch 48/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4697 - accuracy: 0.8098\n",
      "Epoch 48: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4674 - accuracy: 0.8102 - val_loss: 0.4511 - val_accuracy: 0.8115\n",
      "Epoch 49/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.4341 - accuracy: 0.8282\n",
      "Epoch 49: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4335 - accuracy: 0.8283 - val_loss: 0.4272 - val_accuracy: 0.8293\n",
      "Epoch 50/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4240 - accuracy: 0.8333\n",
      "Epoch 50: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4236 - accuracy: 0.8332 - val_loss: 0.4190 - val_accuracy: 0.8339\n",
      "Epoch 51/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4225 - accuracy: 0.8335\n",
      "Epoch 51: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4223 - accuracy: 0.8337 - val_loss: 0.4143 - val_accuracy: 0.8342\n",
      "Epoch 52/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4156 - accuracy: 0.8351\n",
      "Epoch 52: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4163 - accuracy: 0.8346 - val_loss: 0.4116 - val_accuracy: 0.8345\n",
      "Epoch 53/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4137 - accuracy: 0.8347\n",
      "Epoch 53: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4133 - accuracy: 0.8349 - val_loss: 0.4097 - val_accuracy: 0.8350\n",
      "Epoch 54/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4164 - accuracy: 0.8333\n",
      "Epoch 54: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4185 - accuracy: 0.8326 - val_loss: 0.4120 - val_accuracy: 0.8345\n",
      "Epoch 55/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4194 - accuracy: 0.8304\n",
      "Epoch 55: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4199 - accuracy: 0.8303 - val_loss: 0.4209 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4138 - accuracy: 0.8341\n",
      "Epoch 56: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4142 - accuracy: 0.8338 - val_loss: 0.4113 - val_accuracy: 0.8341\n",
      "Epoch 57/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4673 - accuracy: 0.8072\n",
      "Epoch 57: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4790 - accuracy: 0.7819 - val_loss: 0.6957 - val_accuracy: 0.5007\n",
      "Epoch 58/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.5843 - accuracy: 0.6798\n",
      "Epoch 58: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5746 - accuracy: 0.6921 - val_loss: 0.4547 - val_accuracy: 0.8216\n",
      "Epoch 59/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4472 - accuracy: 0.8099\n",
      "Epoch 59: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4454 - accuracy: 0.8115 - val_loss: 0.4194 - val_accuracy: 0.8320\n",
      "Epoch 60/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4109 - accuracy: 0.8316\n",
      "Epoch 60: val_loss did not improve from 0.40317\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4100 - accuracy: 0.8321 - val_loss: 0.4053 - val_accuracy: 0.8344\n",
      "Epoch 61/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4079 - accuracy: 0.8348\n",
      "Epoch 61: val_loss improved from 0.40317 to 0.40314, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4079 - accuracy: 0.8345 - val_loss: 0.4031 - val_accuracy: 0.8352\n",
      "Epoch 62/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4083 - accuracy: 0.8338\n",
      "Epoch 62: val_loss improved from 0.40314 to 0.40154, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4088 - accuracy: 0.8337 - val_loss: 0.4015 - val_accuracy: 0.8354\n",
      "Epoch 63/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4036 - accuracy: 0.8351\n",
      "Epoch 63: val_loss improved from 0.40154 to 0.39954, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4036 - accuracy: 0.8351 - val_loss: 0.3995 - val_accuracy: 0.8359\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8358\n",
      "Epoch 64: val_loss improved from 0.39954 to 0.39884, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4020 - accuracy: 0.8358 - val_loss: 0.3988 - val_accuracy: 0.8363\n",
      "Epoch 65/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4036 - accuracy: 0.8354\n",
      "Epoch 65: val_loss improved from 0.39884 to 0.39827, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4030 - accuracy: 0.8355 - val_loss: 0.3983 - val_accuracy: 0.8363\n",
      "Epoch 66/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4083 - accuracy: 0.8328\n",
      "Epoch 66: val_loss did not improve from 0.39827\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4154 - accuracy: 0.8292 - val_loss: 0.4720 - val_accuracy: 0.8065\n",
      "Epoch 67/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4400 - accuracy: 0.8197\n",
      "Epoch 67: val_loss did not improve from 0.39827\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4385 - accuracy: 0.8211 - val_loss: 0.4124 - val_accuracy: 0.8337\n",
      "Epoch 68/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4068 - accuracy: 0.8319\n",
      "Epoch 68: val_loss did not improve from 0.39827\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4071 - accuracy: 0.8317 - val_loss: 0.3996 - val_accuracy: 0.8353\n",
      "Epoch 69/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3999 - accuracy: 0.8365\n",
      "Epoch 69: val_loss improved from 0.39827 to 0.39730, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.4000 - accuracy: 0.8366 - val_loss: 0.3973 - val_accuracy: 0.8376\n",
      "Epoch 70/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3991 - accuracy: 0.8373\n",
      "Epoch 70: val_loss did not improve from 0.39730\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3996 - accuracy: 0.8374 - val_loss: 0.3982 - val_accuracy: 0.8371\n",
      "Epoch 71/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3983 - accuracy: 0.8376\n",
      "Epoch 71: val_loss improved from 0.39730 to 0.39477, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3991 - accuracy: 0.8372 - val_loss: 0.3948 - val_accuracy: 0.8380\n",
      "Epoch 72/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4036 - accuracy: 0.8339\n",
      "Epoch 72: val_loss did not improve from 0.39477\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4031 - accuracy: 0.8342 - val_loss: 0.3963 - val_accuracy: 0.8379\n",
      "Epoch 73/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3985 - accuracy: 0.8368\n",
      "Epoch 73: val_loss improved from 0.39477 to 0.39446, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3981 - accuracy: 0.8370 - val_loss: 0.3945 - val_accuracy: 0.8383\n",
      "Epoch 74/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3983 - accuracy: 0.8377\n",
      "Epoch 74: val_loss did not improve from 0.39446\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3981 - accuracy: 0.8377 - val_loss: 0.3965 - val_accuracy: 0.8366\n",
      "Epoch 75/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3975 - accuracy: 0.8378\n",
      "Epoch 75: val_loss did not improve from 0.39446\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3972 - accuracy: 0.8378 - val_loss: 0.3954 - val_accuracy: 0.8368\n",
      "Epoch 76/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4002 - accuracy: 0.8364\n",
      "Epoch 76: val_loss improved from 0.39446 to 0.39288, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3998 - accuracy: 0.8364 - val_loss: 0.3929 - val_accuracy: 0.8381\n",
      "Epoch 77/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3964 - accuracy: 0.8375\n",
      "Epoch 77: val_loss improved from 0.39288 to 0.39235, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3956 - accuracy: 0.8379 - val_loss: 0.3924 - val_accuracy: 0.8386\n",
      "Epoch 78/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3959 - accuracy: 0.8381\n",
      "Epoch 78: val_loss did not improve from 0.39235\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3954 - accuracy: 0.8385 - val_loss: 0.3942 - val_accuracy: 0.8386\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8384\n",
      "Epoch 79: val_loss did not improve from 0.39235\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3955 - accuracy: 0.8384 - val_loss: 0.3926 - val_accuracy: 0.8392\n",
      "Epoch 80/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3959 - accuracy: 0.8387\n",
      "Epoch 80: val_loss did not improve from 0.39235\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3956 - accuracy: 0.8388 - val_loss: 0.3932 - val_accuracy: 0.8391\n",
      "Epoch 81/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3950 - accuracy: 0.8388\n",
      "Epoch 81: val_loss improved from 0.39235 to 0.39170, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3950 - accuracy: 0.8388 - val_loss: 0.3917 - val_accuracy: 0.8394\n",
      "Epoch 82/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3951 - accuracy: 0.8389\n",
      "Epoch 82: val_loss improved from 0.39170 to 0.39143, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3945 - accuracy: 0.8390 - val_loss: 0.3914 - val_accuracy: 0.8397\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3950 - accuracy: 0.8382\n",
      "Epoch 83: val_loss improved from 0.39143 to 0.39101, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3945 - accuracy: 0.8385 - val_loss: 0.3910 - val_accuracy: 0.8390\n",
      "Epoch 84/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3942 - accuracy: 0.8385\n",
      "Epoch 84: val_loss did not improve from 0.39101\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3940 - accuracy: 0.8388 - val_loss: 0.3942 - val_accuracy: 0.8394\n",
      "Epoch 85/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3956 - accuracy: 0.8391\n",
      "Epoch 85: val_loss did not improve from 0.39101\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3957 - accuracy: 0.8388 - val_loss: 0.3911 - val_accuracy: 0.8395\n",
      "Epoch 86/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3953 - accuracy: 0.8388\n",
      "Epoch 86: val_loss did not improve from 0.39101\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3951 - accuracy: 0.8385 - val_loss: 0.3915 - val_accuracy: 0.8393\n",
      "Epoch 87/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3934 - accuracy: 0.8392\n",
      "Epoch 87: val_loss improved from 0.39101 to 0.39012, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3931 - accuracy: 0.8393 - val_loss: 0.3901 - val_accuracy: 0.8401\n",
      "Epoch 88/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3929 - accuracy: 0.8392\n",
      "Epoch 88: val_loss improved from 0.39012 to 0.39011, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3927 - accuracy: 0.8394 - val_loss: 0.3901 - val_accuracy: 0.8396\n",
      "Epoch 89/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3923 - accuracy: 0.8392\n",
      "Epoch 89: val_loss did not improve from 0.39011\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3923 - accuracy: 0.8394 - val_loss: 0.3915 - val_accuracy: 0.8391\n",
      "Epoch 90/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3928 - accuracy: 0.8389\n",
      "Epoch 90: val_loss improved from 0.39011 to 0.38913, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3933 - accuracy: 0.8388 - val_loss: 0.3891 - val_accuracy: 0.8403\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8397\n",
      "Epoch 91: val_loss improved from 0.38913 to 0.38877, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3922 - accuracy: 0.8397 - val_loss: 0.3888 - val_accuracy: 0.8407\n",
      "Epoch 92/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3921 - accuracy: 0.8394\n",
      "Epoch 92: val_loss did not improve from 0.38877\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3919 - accuracy: 0.8395 - val_loss: 0.3889 - val_accuracy: 0.8407\n",
      "Epoch 93/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3918 - accuracy: 0.8397\n",
      "Epoch 93: val_loss did not improve from 0.38877\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3922 - accuracy: 0.8397 - val_loss: 0.3904 - val_accuracy: 0.8396\n",
      "Epoch 94/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4201 - accuracy: 0.8271\n",
      "Epoch 94: val_loss did not improve from 0.38877\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4186 - accuracy: 0.8279 - val_loss: 0.3913 - val_accuracy: 0.8387\n",
      "Epoch 95/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3949 - accuracy: 0.8371\n",
      "Epoch 95: val_loss improved from 0.38877 to 0.38805, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3949 - accuracy: 0.8372 - val_loss: 0.3880 - val_accuracy: 0.8405\n",
      "Epoch 96/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3906 - accuracy: 0.8402\n",
      "Epoch 96: val_loss improved from 0.38805 to 0.38767, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3904 - accuracy: 0.8401 - val_loss: 0.3877 - val_accuracy: 0.8407\n",
      "Epoch 97/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3914 - accuracy: 0.8398\n",
      "Epoch 97: val_loss did not improve from 0.38767\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3905 - accuracy: 0.8401 - val_loss: 0.3881 - val_accuracy: 0.8411\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8371\n",
      "Epoch 98: val_loss did not improve from 0.38767\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3974 - accuracy: 0.8371 - val_loss: 0.3897 - val_accuracy: 0.8409\n",
      "Epoch 99/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4351 - accuracy: 0.8187\n",
      "Epoch 99: val_loss did not improve from 0.38767\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4319 - accuracy: 0.8210 - val_loss: 0.4241 - val_accuracy: 0.8346\n",
      "Epoch 100/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.4064 - accuracy: 0.8337\n",
      "Epoch 100: val_loss did not improve from 0.38767\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8344 - val_loss: 0.3943 - val_accuracy: 0.8393\n",
      "Epoch 101/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3954 - accuracy: 0.8380\n",
      "Epoch 101: val_loss did not improve from 0.38767\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3950 - accuracy: 0.8382 - val_loss: 0.3925 - val_accuracy: 0.8379\n",
      "Epoch 102/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3918 - accuracy: 0.8394\n",
      "Epoch 102: val_loss improved from 0.38767 to 0.38634, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3918 - accuracy: 0.8392 - val_loss: 0.3863 - val_accuracy: 0.8412\n",
      "Epoch 103/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3899 - accuracy: 0.8400\n",
      "Epoch 103: val_loss did not improve from 0.38634\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3907 - accuracy: 0.8396 - val_loss: 0.3895 - val_accuracy: 0.8414\n",
      "Epoch 104/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3916 - accuracy: 0.8392\n",
      "Epoch 104: val_loss did not improve from 0.38634\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3916 - accuracy: 0.8391 - val_loss: 0.3868 - val_accuracy: 0.8412\n",
      "Epoch 105/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3896 - accuracy: 0.8403\n",
      "Epoch 105: val_loss did not improve from 0.38634\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3893 - accuracy: 0.8405 - val_loss: 0.3869 - val_accuracy: 0.8408\n",
      "Epoch 106/150\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.3925 - accuracy: 0.8394\n",
      "Epoch 106: val_loss did not improve from 0.38634\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3930 - accuracy: 0.8391 - val_loss: 0.3982 - val_accuracy: 0.8354\n",
      "Epoch 107/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3930 - accuracy: 0.8391\n",
      "Epoch 107: val_loss did not improve from 0.38634\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3924 - accuracy: 0.8390 - val_loss: 0.3867 - val_accuracy: 0.8417\n",
      "Epoch 108/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3896 - accuracy: 0.8404\n",
      "Epoch 108: val_loss improved from 0.38634 to 0.38504, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3893 - accuracy: 0.8406 - val_loss: 0.3850 - val_accuracy: 0.8415\n",
      "Epoch 109/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3888 - accuracy: 0.8404\n",
      "Epoch 109: val_loss did not improve from 0.38504\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3886 - accuracy: 0.8405 - val_loss: 0.3870 - val_accuracy: 0.8412\n",
      "Epoch 110/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3891 - accuracy: 0.8409\n",
      "Epoch 110: val_loss did not improve from 0.38504\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3887 - accuracy: 0.8411 - val_loss: 0.3851 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3887 - accuracy: 0.8401\n",
      "Epoch 111: val_loss did not improve from 0.38504\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3883 - accuracy: 0.8403 - val_loss: 0.3851 - val_accuracy: 0.8421\n",
      "Epoch 112/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3870 - accuracy: 0.8411\n",
      "Epoch 112: val_loss improved from 0.38504 to 0.38475, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3877 - accuracy: 0.8409 - val_loss: 0.3848 - val_accuracy: 0.8420\n",
      "Epoch 113/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3886 - accuracy: 0.8402\n",
      "Epoch 113: val_loss did not improve from 0.38475\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3882 - accuracy: 0.8405 - val_loss: 0.3856 - val_accuracy: 0.8418\n",
      "Epoch 114/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3893 - accuracy: 0.8404\n",
      "Epoch 114: val_loss improved from 0.38475 to 0.38444, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3889 - accuracy: 0.8405 - val_loss: 0.3844 - val_accuracy: 0.8421\n",
      "Epoch 115/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3902 - accuracy: 0.8396\n",
      "Epoch 115: val_loss did not improve from 0.38444\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3910 - accuracy: 0.8391 - val_loss: 0.3881 - val_accuracy: 0.8403\n",
      "Epoch 116/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3892 - accuracy: 0.8403\n",
      "Epoch 116: val_loss did not improve from 0.38444\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3892 - accuracy: 0.8404 - val_loss: 0.3852 - val_accuracy: 0.8421\n",
      "Epoch 117/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3901 - accuracy: 0.8397\n",
      "Epoch 117: val_loss improved from 0.38444 to 0.38437, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3893 - accuracy: 0.8400 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
      "Epoch 118/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3857 - accuracy: 0.8418\n",
      "Epoch 118: val_loss did not improve from 0.38437\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3862 - accuracy: 0.8416 - val_loss: 0.3861 - val_accuracy: 0.8413\n",
      "Epoch 119/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3874 - accuracy: 0.8407\n",
      "Epoch 119: val_loss improved from 0.38437 to 0.38397, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3871 - accuracy: 0.8409 - val_loss: 0.3840 - val_accuracy: 0.8427\n",
      "Epoch 120/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3882 - accuracy: 0.8409\n",
      "Epoch 120: val_loss did not improve from 0.38397\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3882 - accuracy: 0.8408 - val_loss: 0.3851 - val_accuracy: 0.8427\n",
      "Epoch 121/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3865 - accuracy: 0.8419\n",
      "Epoch 121: val_loss improved from 0.38397 to 0.38361, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3863 - accuracy: 0.8416 - val_loss: 0.3836 - val_accuracy: 0.8429\n",
      "Epoch 122/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3859 - accuracy: 0.8416\n",
      "Epoch 122: val_loss improved from 0.38361 to 0.38277, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3857 - accuracy: 0.8418 - val_loss: 0.3828 - val_accuracy: 0.8431\n",
      "Epoch 123/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3846 - accuracy: 0.8423\n",
      "Epoch 123: val_loss improved from 0.38277 to 0.38219, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3850 - accuracy: 0.8421 - val_loss: 0.3822 - val_accuracy: 0.8427\n",
      "Epoch 124/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3853 - accuracy: 0.8418\n",
      "Epoch 124: val_loss did not improve from 0.38219\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3856 - accuracy: 0.8417 - val_loss: 0.3827 - val_accuracy: 0.8424\n",
      "Epoch 125/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3849 - accuracy: 0.8421\n",
      "Epoch 125: val_loss did not improve from 0.38219\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3853 - accuracy: 0.8419 - val_loss: 0.3823 - val_accuracy: 0.8432\n",
      "Epoch 126/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3861 - accuracy: 0.8412\n",
      "Epoch 126: val_loss improved from 0.38219 to 0.38209, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3852 - accuracy: 0.8418 - val_loss: 0.3821 - val_accuracy: 0.8433\n",
      "Epoch 127/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3845 - accuracy: 0.8420\n",
      "Epoch 127: val_loss improved from 0.38209 to 0.38156, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3848 - accuracy: 0.8420 - val_loss: 0.3816 - val_accuracy: 0.8429\n",
      "Epoch 128/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3841 - accuracy: 0.8425\n",
      "Epoch 128: val_loss improved from 0.38156 to 0.38148, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3843 - accuracy: 0.8424 - val_loss: 0.3815 - val_accuracy: 0.8430\n",
      "Epoch 129/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3840 - accuracy: 0.8426\n",
      "Epoch 129: val_loss improved from 0.38148 to 0.38119, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3845 - accuracy: 0.8424 - val_loss: 0.3812 - val_accuracy: 0.8430\n",
      "Epoch 130/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3848 - accuracy: 0.8418\n",
      "Epoch 130: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3848 - accuracy: 0.8419 - val_loss: 0.3819 - val_accuracy: 0.8429\n",
      "Epoch 131/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3845 - accuracy: 0.8421\n",
      "Epoch 131: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3844 - accuracy: 0.8420 - val_loss: 0.3816 - val_accuracy: 0.8428\n",
      "Epoch 132/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.5802 - accuracy: 0.6924\n",
      "Epoch 132: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.6114 - accuracy: 0.6659 - val_loss: 0.7560 - val_accuracy: 0.5007\n",
      "Epoch 133/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.6450 - accuracy: 0.5605\n",
      "Epoch 133: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.6408 - accuracy: 0.5596 - val_loss: 0.5800 - val_accuracy: 0.6871\n",
      "Epoch 134/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.5480 - accuracy: 0.8183\n",
      "Epoch 134: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.5418 - accuracy: 0.8198 - val_loss: 0.4916 - val_accuracy: 0.8357\n",
      "Epoch 135/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4629 - accuracy: 0.8362\n",
      "Epoch 135: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.4605 - accuracy: 0.8365 - val_loss: 0.4272 - val_accuracy: 0.8393\n",
      "Epoch 136/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.4118 - accuracy: 0.8382\n",
      "Epoch 136: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.4105 - accuracy: 0.8382 - val_loss: 0.3905 - val_accuracy: 0.8404\n",
      "Epoch 137/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3874 - accuracy: 0.8405\n",
      "Epoch 137: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3880 - accuracy: 0.8403 - val_loss: 0.3894 - val_accuracy: 0.8391\n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3875 - accuracy: 0.8397\n",
      "Epoch 138: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3870 - accuracy: 0.8400 - val_loss: 0.3823 - val_accuracy: 0.8417\n",
      "Epoch 139/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3854 - accuracy: 0.8410\n",
      "Epoch 139: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3852 - accuracy: 0.8411 - val_loss: 0.3817 - val_accuracy: 0.8421\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8414\n",
      "Epoch 140: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3845 - accuracy: 0.8414 - val_loss: 0.3814 - val_accuracy: 0.8422\n",
      "Epoch 141/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3843 - accuracy: 0.8414\n",
      "Epoch 141: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.8415 - val_loss: 0.3815 - val_accuracy: 0.8423\n",
      "Epoch 142/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3844 - accuracy: 0.8416\n",
      "Epoch 142: val_loss did not improve from 0.38119\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.8416 - val_loss: 0.3813 - val_accuracy: 0.8422\n",
      "Epoch 143/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3849 - accuracy: 0.8413\n",
      "Epoch 143: val_loss improved from 0.38119 to 0.38050, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3843 - accuracy: 0.8416 - val_loss: 0.3805 - val_accuracy: 0.8425\n",
      "Epoch 144/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3834 - accuracy: 0.8420\n",
      "Epoch 144: val_loss improved from 0.38050 to 0.38022, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3836 - accuracy: 0.8418 - val_loss: 0.3802 - val_accuracy: 0.8427\n",
      "Epoch 145/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3831 - accuracy: 0.8419\n",
      "Epoch 145: val_loss improved from 0.38022 to 0.38014, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3833 - accuracy: 0.8418 - val_loss: 0.3801 - val_accuracy: 0.8426\n",
      "Epoch 146/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3840 - accuracy: 0.8416\n",
      "Epoch 146: val_loss improved from 0.38014 to 0.37988, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3833 - accuracy: 0.8420 - val_loss: 0.3799 - val_accuracy: 0.8429\n",
      "Epoch 147/150\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.3827 - accuracy: 0.8420\n",
      "Epoch 147: val_loss improved from 0.37988 to 0.37975, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3832 - accuracy: 0.8419 - val_loss: 0.3798 - val_accuracy: 0.8428\n",
      "Epoch 148/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3821 - accuracy: 0.8426\n",
      "Epoch 148: val_loss improved from 0.37975 to 0.37967, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3829 - accuracy: 0.8422 - val_loss: 0.3797 - val_accuracy: 0.8432\n",
      "Epoch 149/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3826 - accuracy: 0.8426\n",
      "Epoch 149: val_loss improved from 0.37967 to 0.37947, saving model to qlstm_4int_test3\\model_qlstm_14frac.h5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.3829 - accuracy: 0.8423 - val_loss: 0.3795 - val_accuracy: 0.8433\n",
      "Epoch 150/150\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.3828 - accuracy: 0.8421\n",
      "Epoch 150: val_loss did not improve from 0.37947\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3825 - accuracy: 0.8424 - val_loss: 0.3797 - val_accuracy: 0.8432\n",
      "624/624 [==============================] - 4s 5ms/step\n",
      "0.9057821823001705\n"
     ]
    }
   ],
   "source": [
    "# LSTM_2int = []\n",
    "# LSTM_4int = []\n",
    "for j in [4]:\n",
    "    for i in [14]:\n",
    "        int_bits = j\n",
    "        total_bits = i + int_bits + 1\n",
    "        config = {\n",
    "            \"QLSTM\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"bias_quantizer\" : f\"quantized_bits({total_bits}, {int_bits},1)\",\n",
    "                 \"recurrent_quantizer\": f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"state_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"QDense\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                \"bias_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"relu_0\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "            \"relu_1\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "        }\n",
    "    \n",
    "        qmodel = model_quantize(model, config, total_bits, transfer_weights=True)\n",
    "        qmodel.summary()\n",
    "        \n",
    "        es = EarlyStopping(monitor='val_loss',min_delta = 1e-4, mode='min', verbose=1, patience=150)\n",
    "        adam = Adam(lr = 0.0002)\n",
    "    \n",
    "        qmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = qmodel.fit(x_train.astype('float32'), y_train.astype('float32'), \n",
    "                    batch_size = 2**14,\n",
    "                    epochs = 150, \n",
    "                    validation_split = 0.2, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [ModelCheckpoint(f'qlstm_{j}int_test3/model_qlstm_{i}frac.h5', verbose=1, save_best_only=True), es],\n",
    "                    use_multiprocessing=True, workers=4)\n",
    "        \n",
    "        labels = ['j_t']\n",
    "        y_keras = qmodel.predict(x_test)\n",
    "        auc_score = roc_auc_score(y_test, y_keras)\n",
    "        print(auc_score)\n",
    "#         if j == 2:\n",
    "#             LSTM_2int.append(auc_score)\n",
    "#         else:\n",
    "#             LSTM_4int.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "457e7583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8977946415000806, 0.9074863424189847, 0.9095324922817647, 0.9204501103592764, 0.9191139183414114, 0.9154971330948511, 0.9179890956826402]\n"
     ]
    }
   ],
   "source": [
    "print(LSTM_2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3f7ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_2int = [0.8977946415000806, 0.9074863424189847, 0.9095324922817647, 0.9204501103592764, 0.9191139183414114, 0.9154971330948511, 0.9179890956826402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d345d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_4int = [0.8991893928549448, 0.9025749104264241, 0.9195204268675183, 0.9204524318294748, 0.9198742651541856, 0.9123245878023645, 0.9057821823001705]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27974df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8991893928549448, 0.9025749104264241, 0.9195204268675183, 0.9204524318294748, 0.9198742651541856, 0.9123245878023645, 0.9057821823001705]\n"
     ]
    }
   ],
   "source": [
    "print(LSTM_4int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f73b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 2s 2ms/step\n",
      "0.9207847688802558\n"
     ]
    }
   ],
   "source": [
    "lstm = load_model('lstm/model_toptag_lstm.h5')\n",
    "labels = ['j_t']\n",
    "y_keras = lstm.predict(x_test)\n",
    "auc_score = roc_auc_score(y_test, y_keras)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6bb820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.95)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_float = [0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558]\n",
    "plt.plot([2,4,6,8,10,12,14], lstm_float, \"-\", label = \"floating point\")\n",
    "plt.plot([2,4,6,8,10,12,14], LSTM_2int, \"-o\", label = '2 int')\n",
    "plt.plot([2,4,6,8,10,12,14], LSTM_4int, \"-o\", label = '4 int')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"fractional bits\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"QLSTM QAT\")\n",
    "plt.grid()\n",
    "plt.ylim([0.5, 0.95]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d557c6",
   "metadata": {},
   "source": [
    "## QLSTM weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ab83e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer1': {'weights': [array([[-0.4375  , -0.25    , -0.25    ,  0.3125  ,  0.      ,  0.      ,\n",
       "           -0.3125  ,  0.125   ,  0.1875  , -0.375   , -0.25    ,  0.375   ,\n",
       "            0.03125 ,  0.28125 ,  0.25    ,  0.03125 ,  0.      , -0.46875 ,\n",
       "            0.0625  , -0.3125  ,  0.0625  , -0.0625  , -0.25    ,  0.1875  ,\n",
       "           -0.03125 ,  0.0625  ,  0.09375 ,  0.0625  ,  0.375   ,  0.3125  ,\n",
       "           -0.46875 , -0.375   ,  0.25    , -0.125   , -0.1875  , -0.375   ,\n",
       "           -0.5     , -0.5625  ,  0.0625  ,  0.375   ,  0.625   , -0.375   ,\n",
       "           -0.375   , -0.1875  ,  0.25    , -0.25    , -0.125   ,  0.34375 ,\n",
       "           -0.5     ,  0.3125  , -0.125   ,  0.25    , -0.375   , -0.46875 ,\n",
       "            0.      ,  0.0625  , -0.25    , -0.8125  , -0.1875  , -0.9375  ,\n",
       "            0.125   ,  0.46875 , -0.0625  ,  0.125   ,  0.      ,  0.      ,\n",
       "            0.0625  , -0.21875 ,  0.0625  ,  0.5     , -0.125   ,  0.21875 ,\n",
       "           -0.1875  , -0.0625  ,  0.125   , -0.0625  ,  0.0625  , -0.375   ,\n",
       "            0.25    , -0.15625 ],\n",
       "          [ 0.0625  , -0.1875  ,  0.25    , -0.0625  , -0.234375,  0.      ,\n",
       "           -0.0625  ,  0.75    ,  0.1875  ,  0.      ,  0.5625  ,  0.6875  ,\n",
       "           -0.03125 , -0.46875 ,  0.34375 , -0.15625 ,  0.0625  ,  0.0625  ,\n",
       "            0.28125 ,  0.875   ,  0.25    ,  0.      ,  0.5     , -0.6875  ,\n",
       "            0.03125 ,  0.375   ,  0.46875 ,  0.09375 , -0.625   , -0.5625  ,\n",
       "           -0.3125  , -0.8125  ,  0.3125  , -0.234375,  0.375   , -0.09375 ,\n",
       "           -0.3125  ,  0.125   , -0.5     , -0.125   ,  0.5     , -0.375   ,\n",
       "            0.25    ,  0.5     , -0.46875 ,  0.0625  ,  0.25    ,  0.46875 ,\n",
       "            0.125   , -0.6875  , -0.875   ,  0.125   , -0.875   ,  0.46875 ,\n",
       "           -0.25    , -0.0625  ,  0.875   ,  0.5     , -0.1875  ,  0.125   ,\n",
       "            0.      ,  0.15625 ,  0.      ,  0.875   , -0.4375  , -0.078125,\n",
       "            0.0625  ,  0.46875 , -0.0625  , -0.4375  ,  0.3125  ,  0.4375  ,\n",
       "            0.375   , -0.125   ,  0.75    ,  0.21875 ,  0.625   ,  0.25    ,\n",
       "           -0.0625  ,  0.03125 ],\n",
       "          [-0.375   , -0.46875 ,  0.375   , -0.125   ,  0.234375, -0.0625  ,\n",
       "            0.3125  , -0.375   ,  0.125   ,  0.5625  ,  0.4375  ,  0.      ,\n",
       "           -0.1875  , -0.15625 ,  0.03125 ,  0.      ,  0.4375  , -0.15625 ,\n",
       "            0.1875  , -0.625   ,  0.375   ,  0.5     , -0.5     , -0.0625  ,\n",
       "           -0.1875  ,  0.125   , -0.3125  ,  0.234375, -0.375   ,  0.3125  ,\n",
       "           -0.0625  ,  0.625   , -0.8125  , -0.15625 , -0.1875  ,  0.46875 ,\n",
       "           -0.125   ,  0.0625  ,  0.      ,  0.125   ,  0.6875  ,  0.125   ,\n",
       "            0.75    , -0.3125  ,  0.375   ,  0.5     , -0.125   , -0.25    ,\n",
       "            0.25    , -0.0625  , -0.1875  ,  0.125   ,  0.875   ,  0.      ,\n",
       "            0.125   , -0.125   ,  0.0625  , -0.5625  , -0.0625  , -0.0625  ,\n",
       "            0.125   ,  0.03125 ,  0.375   , -0.5625  ,  0.28125 , -0.015625,\n",
       "            0.75    , -0.46875 , -0.5     , -0.125   ,  0.6875  , -0.125   ,\n",
       "            0.375   ,  0.40625 ,  0.      ,  0.125   ,  0.0625  ,  0.6875  ,\n",
       "           -0.5     , -0.25    ],\n",
       "          [ 0.3125  , -0.25    ,  0.5625  ,  0.3125  ,  0.      ,  0.125   ,\n",
       "            0.      ,  0.0625  ,  0.25    ,  0.125   , -0.375   ,  0.375   ,\n",
       "            0.03125 ,  0.03125 ,  0.0625  , -0.375   , -0.1875  , -0.375   ,\n",
       "           -0.25    , -0.125   ,  0.0625  ,  0.125   , -0.375   , -0.0625  ,\n",
       "           -0.03125 ,  0.0625  ,  0.46875 ,  0.078125,  0.5     ,  0.3125  ,\n",
       "            0.15625 , -0.0625  , -0.1875  ,  0.046875, -0.5     , -0.4375  ,\n",
       "           -0.375   , -0.5625  ,  0.3125  ,  0.1875  ,  0.1875  , -0.625   ,\n",
       "            0.125   ,  0.125   , -0.3125  ,  0.0625  ,  0.25    , -0.0625  ,\n",
       "           -0.25    ,  0.4375  , -0.25    , -0.125   , -0.375   , -0.09375 ,\n",
       "            0.375   , -0.25    ,  0.3125  , -0.0625  , -0.375   , -0.9375  ,\n",
       "            0.375   ,  0.34375 , -0.6875  ,  0.0625  ,  0.      ,  0.      ,\n",
       "           -0.125   ,  0.21875 ,  0.25    , -0.125   ,  0.      ,  0.46875 ,\n",
       "            0.4375  ,  0.125   , -0.1875  , -0.1875  , -0.0625  , -0.5     ,\n",
       "            0.5     , -0.09375 ],\n",
       "          [ 0.9375  ,  0.46875 , -0.9375  ,  0.8125  ,  0.      ,  0.      ,\n",
       "           -0.8125  , -0.0625  ,  0.625   ,  0.9375  , -0.9375  , -0.0625  ,\n",
       "            0.46875 ,  0.      , -0.21875 , -0.34375 , -0.375   , -0.46875 ,\n",
       "            0.34375 ,  0.5625  ,  0.9375  ,  0.6875  , -1.5     ,  0.1875  ,\n",
       "            0.      ,  0.      , -0.28125 ,  0.171875,  1.875   ,  0.9375  ,\n",
       "           -0.46875 , -0.9375  ,  0.9375  ,  0.15625 , -0.6875  , -0.4375  ,\n",
       "           -0.9375  , -0.6875  ,  0.75    ,  0.9375  ,  0.5625  , -1.875   ,\n",
       "           -1.875   , -0.9375  ,  0.28125 ,  0.9375  , -0.6875  ,  0.4375  ,\n",
       "           -1.75    , -0.3125  ,  0.9375  , -1.75    , -1.875   ,  0.46875 ,\n",
       "           -0.9375  , -0.9375  , -0.9375  , -0.9375  , -0.9375  , -0.5     ,\n",
       "            1.5     ,  0.46875 , -0.9375  ,  0.5     ,  0.      ,  0.      ,\n",
       "           -0.625   ,  0.21875 ,  0.9375  ,  0.875   , -0.9375  , -0.46875 ,\n",
       "            0.8125  ,  0.28125 , -0.375   , -0.46875 , -0.9375  , -0.4375  ,\n",
       "            0.75    ,  0.46875 ],\n",
       "          [-0.1875  ,  0.28125 ,  0.25    ,  0.3125  , -0.140625,  0.375   ,\n",
       "            0.625   ,  0.25    ,  0.9375  , -0.125   , -0.0625  ,  0.1875  ,\n",
       "            0.46875 ,  0.      ,  0.46875 ,  0.0625  ,  0.75    , -0.1875  ,\n",
       "            0.46875 ,  0.1875  , -0.3125  ,  0.4375  , -0.5     , -0.125   ,\n",
       "            0.4375  , -0.28125 ,  0.3125  , -0.09375 ,  0.25    ,  0.      ,\n",
       "            0.21875 , -0.1875  , -0.625   , -0.03125 ,  0.1875  ,  0.3125  ,\n",
       "            0.5625  ,  0.125   ,  0.      ,  0.      ,  0.1875  , -0.125   ,\n",
       "            0.625   , -0.875   ,  0.46875 , -0.25    ,  0.5     , -0.09375 ,\n",
       "           -0.375   , -0.6875  ,  0.      ,  0.125   , -0.75    ,  0.      ,\n",
       "            0.4375  ,  0.6875  ,  0.      ,  0.5     ,  0.1875  , -0.875   ,\n",
       "            0.875   , -0.28125 , -0.125   , -0.1875  , -0.25    ,  0.234375,\n",
       "            0.25    , -0.34375 , -0.5     , -0.0625  ,  0.3125  ,  0.25    ,\n",
       "            0.125   ,  0.15625 , -0.1875  , -0.09375 ,  0.4375  ,  0.125   ,\n",
       "            0.1875  ,  0.28125 ]], dtype=float32),\n",
       "   array([[ 0.15625 ,  0.46875 ,  0.03125 , ...,  0.171875,  0.15625 ,\n",
       "            0.15625 ],\n",
       "          [ 0.1875  , -0.4375  , -0.21875 , ...,  0.      , -0.234375,\n",
       "           -0.25    ],\n",
       "          [ 0.125   ,  0.1875  ,  0.0625  , ...,  0.09375 ,  0.03125 ,\n",
       "            0.21875 ],\n",
       "          ...,\n",
       "          [ 0.09375 ,  0.15625 ,  0.15625 , ...,  0.21875 ,  0.125   ,\n",
       "           -0.03125 ],\n",
       "          [ 0.34375 , -0.46875 , -0.1875  , ..., -0.046875,  0.234375,\n",
       "           -0.25    ],\n",
       "          [ 0.15625 , -0.1875  , -0.1875  , ..., -0.046875,  0.0625  ,\n",
       "           -0.0625  ]], dtype=float32),\n",
       "   array([0.  , 0.25, 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.25, 0.  , 0.  ,\n",
       "          0.25, 0.25, 0.  , 0.  , 0.25, 0.  , 0.25, 0.25, 0.25, 1.  , 1.  ,\n",
       "          1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "          1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.25, 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.25,\n",
       "          0.  , 0.  , 0.25, 0.  , 0.  , 0.25, 0.25, 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.25, 0.25], dtype=float32)]},\n",
       " 'layer3': {'weights': [array([[ 0.109375, -0.125   ,  0.171875, ...,  0.      ,  0.09375 ,\n",
       "            0.21875 ],\n",
       "          [-0.078125, -0.25    , -0.015625, ...,  0.125   ,  0.09375 ,\n",
       "           -0.03125 ],\n",
       "          [-0.0625  , -0.0625  , -0.078125, ...,  0.09375 , -0.1875  ,\n",
       "            0.375   ],\n",
       "          ...,\n",
       "          [-0.015625,  0.125   ,  0.171875, ...,  0.1875  ,  0.      ,\n",
       "            0.03125 ],\n",
       "          [-0.1875  ,  0.4375  , -0.171875, ...,  0.03125 , -0.375   ,\n",
       "           -0.0625  ],\n",
       "          [-0.09375 ,  0.125   , -0.140625, ...,  0.25    , -0.03125 ,\n",
       "            0.0625  ]], dtype=float32),\n",
       "   array([0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "          0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         dtype=float32)]},\n",
       " 'output_sigmoid': {'weights': [array([[ 0.21875],\n",
       "          [-0.46875],\n",
       "          [-0.09375],\n",
       "          [-0.4375 ],\n",
       "          [ 0.21875],\n",
       "          [-0.1875 ],\n",
       "          [-0.15625],\n",
       "          [ 0.34375],\n",
       "          [ 0.     ],\n",
       "          [-0.28125],\n",
       "          [ 0.09375],\n",
       "          [-0.125  ],\n",
       "          [ 0.21875],\n",
       "          [-0.1875 ],\n",
       "          [-0.03125],\n",
       "          [-0.09375],\n",
       "          [ 0.21875],\n",
       "          [-0.25   ],\n",
       "          [-0.28125],\n",
       "          [-0.09375],\n",
       "          [-0.21875],\n",
       "          [-0.3125 ],\n",
       "          [ 0.25   ],\n",
       "          [-0.03125],\n",
       "          [-0.1875 ],\n",
       "          [ 0.03125],\n",
       "          [ 0.28125],\n",
       "          [ 0.1875 ],\n",
       "          [ 0.1875 ],\n",
       "          [-0.28125],\n",
       "          [ 0.25   ],\n",
       "          [-0.1875 ],\n",
       "          [ 0.28125],\n",
       "          [ 0.15625],\n",
       "          [-0.03125],\n",
       "          [ 0.03125],\n",
       "          [-0.15625],\n",
       "          [ 0.15625],\n",
       "          [ 0.15625],\n",
       "          [-0.1875 ],\n",
       "          [ 0.0625 ],\n",
       "          [ 0.09375],\n",
       "          [ 0.15625],\n",
       "          [-0.09375],\n",
       "          [-0.4375 ],\n",
       "          [-0.34375],\n",
       "          [ 0.03125],\n",
       "          [-0.25   ],\n",
       "          [ 0.09375],\n",
       "          [-0.125  ],\n",
       "          [ 0.09375],\n",
       "          [-0.3125 ],\n",
       "          [-0.4375 ],\n",
       "          [-0.21875],\n",
       "          [ 0.21875],\n",
       "          [-0.46875],\n",
       "          [-0.0625 ],\n",
       "          [-0.25   ],\n",
       "          [ 0.21875],\n",
       "          [ 0.03125],\n",
       "          [ 0.1875 ],\n",
       "          [-0.21875],\n",
       "          [-0.1875 ],\n",
       "          [-0.0625 ]], dtype=float32),\n",
       "   array([0.], dtype=float32)]}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlstm = load_model('qlstm_2int_test3/model_qlstm_2frac.h5', custom_objects={'QLSTM': QLSTM, 'QDense': QDense, 'quantized_bits': quantized_bits, 'QActivation': QActivation})\n",
    "model_save_quantized_weights(qlstm, f\"qat2int2fra_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4bea5",
   "metadata": {},
   "source": [
    "## Post Training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd913f8",
   "metadata": {},
   "source": [
    "## QGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "678cf570",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = load_model('gru/model_gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d47c2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 37s 57ms/step\n",
      "0.5944767470490294\n",
      "624/624 [==============================] - 39s 60ms/step\n",
      "0.547488069753607\n",
      "624/624 [==============================] - 37s 58ms/step\n",
      "0.8398998982050393\n",
      "624/624 [==============================] - 36s 57ms/step\n",
      "0.892549626299576\n",
      "624/624 [==============================] - 38s 58ms/step\n",
      "0.8163931733581085\n",
      "624/624 [==============================] - 37s 58ms/step\n",
      "0.817795160464241\n",
      "624/624 [==============================] - 37s 58ms/step\n",
      "0.8192396023359739\n",
      "624/624 [==============================] - 37s 58ms/step\n",
      "0.563519484692306\n",
      "624/624 [==============================] - 40s 62ms/step\n",
      "0.5176656947846756\n",
      "624/624 [==============================] - 41s 63ms/step\n",
      "0.8434171918716625\n",
      "624/624 [==============================] - 40s 62ms/step\n",
      "0.8148832529622261\n",
      "624/624 [==============================] - 40s 63ms/step\n",
      "0.8185849477399875\n",
      "624/624 [==============================] - 41s 63ms/step\n",
      "0.8981746641616495\n",
      "624/624 [==============================] - 40s 62ms/step\n",
      "0.8994407397397951\n"
     ]
    }
   ],
   "source": [
    "GRU_2intptq = []\n",
    "GRU_4intptq = []\n",
    "for j in [2, 4]:\n",
    "    for i in [2, 4, 6, 8, 10, 12, 14]:\n",
    "        int_bits = j\n",
    "        total_bits = i + int_bits + 1\n",
    "        config = {\n",
    "            \"QGRU\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"bias_quantizer\" : f\"quantized_bits({total_bits}, {int_bits},1)\",\n",
    "                 \"recurrent_quantizer\": f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"state_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"QDense\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                \"bias_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"relu_0\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "            \"relu_1\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "        }\n",
    "    \n",
    "        qmodel = model_quantize(gru, config, total_bits, transfer_weights=True)\n",
    "        \n",
    "        labels = ['j_t']\n",
    "        y_keras = qmodel.predict(x_test)\n",
    "        auc_score = roc_auc_score(y_test, y_keras)\n",
    "        print(auc_score)\n",
    "        if j == 2:\n",
    "            GRU_2intptq.append(auc_score)\n",
    "        else:\n",
    "            GRU_4intptq.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed5ab164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5944767470490294, 0.547488069753607, 0.8398998982050393, 0.892549626299576, 0.8163931733581085, 0.817795160464241, 0.8192396023359739]\n"
     ]
    }
   ],
   "source": [
    "print(GRU_2intptq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9955b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_2intptq = [0.5944767470490294, 0.547488069753607, 0.8398998982050393, 0.892549626299576, 0.8163931733581085, 0.817795160464241, 0.8192396023359739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e81d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.563519484692306, 0.5176656947846756, 0.8434171918716625, 0.8148832529622261, 0.8185849477399875, 0.8981746641616495, 0.8994407397397951]\n"
     ]
    }
   ],
   "source": [
    "print(GRU_4intptq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_4intptq = [0.563519484692306, 0.5176656947846756, 0.8434171918716625, 0.8148832529622261, 0.8185849477399875, 0.8981746641616495, 0.8994407397397951]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56ad8024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.95)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "float_gru = [0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996, 0.9307736230093996]\n",
    "plt.plot([2,4,6,8,10,12,14], float_gru, \"-\", label = \"floating point\")\n",
    "plt.plot([2,4,6,8,10,12,14], GRU_2intptq, \"-o\", label = '2 int')\n",
    "plt.plot([2,4,6,8,10,12,14], GRU_4intptq, \"-o\", label = '4 int')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"fractional bits\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"QGRU PTQ\")\n",
    "plt.grid()\n",
    "plt.ylim([0.5, 0.95]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8fba0",
   "metadata": {},
   "source": [
    "## QLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "789da56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = load_model('lstm/model_toptag_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f8d4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 38s 59ms/step\n",
      "0.6665990324916184\n",
      "624/624 [==============================] - 38s 60ms/step\n",
      "0.8023624335954\n",
      "624/624 [==============================] - 38s 60ms/step\n",
      "0.8400666269986702\n",
      "624/624 [==============================] - 39s 60ms/step\n",
      "0.7952402635228453\n",
      "624/624 [==============================] - 38s 59ms/step\n",
      "0.7864280430464492\n",
      "624/624 [==============================] - 38s 60ms/step\n",
      "0.7021665386943657\n",
      "624/624 [==============================] - 39s 60ms/step\n",
      "0.8316973148971215\n",
      "624/624 [==============================] - 40s 61ms/step\n",
      "0.6987813075380407\n",
      "624/624 [==============================] - 39s 60ms/step\n",
      "0.8234192235098241\n",
      "624/624 [==============================] - 38s 59ms/step\n",
      "0.8349360019909571\n",
      "624/624 [==============================] - 38s 59ms/step\n",
      "0.7193770394015198\n",
      "624/624 [==============================] - 38s 59ms/step\n",
      "0.8309812770112103\n",
      "624/624 [==============================] - 39s 60ms/step\n",
      "0.8152388047149924\n",
      "624/624 [==============================] - 39s 59ms/step\n",
      "0.8214026296810437\n"
     ]
    }
   ],
   "source": [
    "LSTM_2intptq = []\n",
    "LSTM_4intptq = []\n",
    "for j in [2, 4]:\n",
    "    for i in [2, 4, 6, 8, 10, 12, 14]:\n",
    "        int_bits = j\n",
    "        total_bits = i + int_bits + 1\n",
    "        config = {\n",
    "            \"QLSTM\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"bias_quantizer\" : f\"quantized_bits({total_bits}, {int_bits},1)\",\n",
    "                 \"recurrent_quantizer\": f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                 \"state_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"QDense\":{\n",
    "                \"kernel_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\",\n",
    "                \"bias_quantizer\" : f\"quantized_bits({total_bits},{int_bits},1)\"\n",
    "            },\n",
    "            \"relu_0\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "            \"relu_1\" : f\"quantized_relu({total_bits},{int_bits},1)\",\n",
    "        }\n",
    "    \n",
    "        qmodel = model_quantize(lstm, config, total_bits, transfer_weights=True)\n",
    "        \n",
    "        labels = ['j_t']\n",
    "        y_keras = qmodel.predict(x_test)\n",
    "        auc_score = roc_auc_score(y_test, y_keras)\n",
    "        print(auc_score)\n",
    "        if j == 2:\n",
    "            LSTM_2intptq.append(auc_score)\n",
    "        else:\n",
    "            LSTM_4intptq.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf30123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6665990324916184, 0.8023624335954, 0.8400666269986702, 0.7952402635228453, 0.7864280430464492, 0.7021665386943657, 0.8316973148971215]\n"
     ]
    }
   ],
   "source": [
    "print(LSTM_2intptq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17526fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_2intptq = [0.6665990324916184, 0.8023624335954, 0.8400666269986702, 0.7952402635228453, 0.7864280430464492, 0.7021665386943657, 0.8316973148971215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92e13b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6987813075380407, 0.8234192235098241, 0.8349360019909571, 0.7193770394015198, 0.8309812770112103, 0.8152388047149924, 0.8214026296810437]\n"
     ]
    }
   ],
   "source": [
    "print(LSTM_4intptq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b1fa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_4intptq = [0.6987813075380407, 0.8234192235098241, 0.8349360019909571, 0.7193770394015198, 0.8309812770112103, 0.8152388047149924, 0.8214026296810437]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "297dd7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.95)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_float = [0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558,0.9207847688802558]\n",
    "plt.plot([2,4,6,8,10,12,14], lstm_float, \"-\", label = \"floating point\")\n",
    "plt.plot([2,4,6,8,10,12,14], LSTM_2intptq, \"-o\", label = '2 int')\n",
    "plt.plot([2,4,6,8,10,12,14], LSTM_4intptq, \"-o\", label = '4 int')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"fractional bits\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"QLSTM PTQ\")\n",
    "plt.grid()\n",
    "plt.ylim([0.5, 0.95]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
